{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjith88697/Bootcamp_Acc/blob/main/Day_8_LLM_foundations_practical_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8db15ed",
      "metadata": {
        "id": "e8db15ed"
      },
      "source": [
        "# Day 8 - LLM foundations & API integration practical tasks\n",
        "***\n",
        "\n",
        "These tasks cover calling Open AI API's and prompting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1d43a7f",
      "metadata": {
        "id": "f1d43a7f"
      },
      "source": [
        "## Explore how different model parameters and different prompts influence the response.\n",
        "#### Here are some guidelines and advices you should consider:\n",
        "* You can add as many cells as is comfortable for you for each answer.\n",
        "* Add a cell and choose a Markdown option in the menu for your conclusions.\n",
        "* You can use both - [Responses API](\"https://platform.openai.com/docs/overview\") and [Chat Completions API](\"https://platform.openai.com/docs/api-reference/chat/create\") - to complete these tasks, but some model parameters are not supported by Responses API.\n",
        "* Keep other parameters constant for the same task and change only those requested in the instructions (e.g., `temperature=1.0`, `max_output_tokens=100`/`max_tokens=100`).\n",
        "* You can copy and paste text from a Markdown cell by pressing Shift or double clicking the cell to enter edit mode.\n",
        "* You can copy and paste API call generated outputs to Markdown cell for enhanced readability (optional).\n",
        "* Be creative and experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bd9d1d51",
      "metadata": {
        "id": "bd9d1d51"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4178071b",
      "metadata": {
        "id": "4178071b"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"########\"\n",
        "\n",
        "# Pass the key directly to the client initialization\n",
        "client = OpenAI(base_url=\"https://ds-ai-internship.openai.azure.com/openai/v1/\",\n",
        "                api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a192841",
      "metadata": {
        "id": "1a192841"
      },
      "source": [
        "\n",
        "#### 1. Write a Python script to call the OpenAI API and generate a response to the prompt below.\n",
        "\n",
        "Prompt: \"What is artificial intelligence?\"\n",
        "\n",
        "Use model `gpt-4.1-mini`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d65ee037",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d65ee037",
        "outputId": "ae0f937d-b0e4-41f1-ce4d-f92ada45743b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response from model:\n",
            "Artificial intelligence (AI) is a branch of computer science focused on creating systems or machines that can perform tasks typically requiring human intelligence. These tasks include learning, reasoning, problem-solving, understanding natural language, recognizing patterns, and making decisions. AI systems use various techniques such as machine learning, neural networks, natural language processing, and computer vision to mimic cognitive functions and improve their performance over time.\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    prompt = \"What is artificial intelligence?\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"Response from model:\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92734ca1",
      "metadata": {
        "id": "92734ca1"
      },
      "source": [
        "#### 2. Call the OpenAI API with different models\n",
        "\n",
        "Prompt \"Explain the concept of machine learning to a 10-year-old.\"\n",
        "\n",
        "`model`: `gpt-4.1-mini` and `gpt-4.1-nano`.\n",
        "\n",
        "Compare the outputs from each model.\n",
        "\n",
        "You can evaluate the differences in:\n",
        "* Clarity of explanation.\n",
        "* Simplicity of language (suitable for a 10-year-old).\n",
        "* Creativity in the response.\n",
        "* Response time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "473f774d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "473f774d",
        "outputId": "f9cc5328-7a6c-4969-b0bf-d8b8d255c5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- gpt-4.1-mini ---\n",
            "Sure! Imagine you have a smart robot friend. Instead of you telling it every single thing to do, you teach it by showing lots of examples. For example, if you want your robot to know what a cat looks like, you show it many pictures of cats. After seeing enough pictures, your robot starts to recognize other cats all by itself. That’s what machine learning is—it's when computers learn from examples and practice, kind of like how you learn at school!\n",
            "\n",
            "Response time: 1.857 seconds\n",
            "\n",
            "--- gpt-4.1-nano ---\n",
            "Sure! Imagine you have a new toy robot that loves to learn new things. At first, it doesn’t know how to do anything, but if you show it lots of examples, it starts figuring out patterns and learns how to do things on its own.\n",
            "\n",
            "For example, if you want the robot to recognize cats in pictures, you show it many pictures of cats and tell it, \"This is a cat,\" and pictures of things that aren’t cats and say, \"This isn’t a cat.\" Over time, the robot learns what makes a picture a cat, like the shape, the color, or the ears.\n",
            "\n",
            "That’s kind of like what machine learning is! It’s a way for computers or robots to learn from examples so they can do things like recognize pictures, understand voice commands, or even play games—all without being told exactly what to do step-by-step. It’s like teaching a machine how to learn on its own!\n",
            "\n",
            "Response time: 1.260 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "def call_model(model_name, prompt):\n",
        "    start = time.time()\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    end = time.time()\n",
        "\n",
        "    text = response.choices[0].message.content\n",
        "    elapsed = end - start\n",
        "    return text, elapsed\n",
        "\n",
        "def main():\n",
        "    prompt = \"Explain the concept of machine learning to a 10-year-old.\"\n",
        "\n",
        "    print(\"\\n--- gpt-4.1-mini ---\")\n",
        "    mini_text, mini_time = call_model(\"gpt-4.1-mini\", prompt)\n",
        "    print(mini_text)\n",
        "    print(f\"\\nResponse time: {mini_time:.3f} seconds\")\n",
        "\n",
        "    print(\"\\n--- gpt-4.1-nano ---\")\n",
        "    nano_text, nano_time = call_model(\"gpt-4.1-nano\", prompt)\n",
        "    print(nano_text)\n",
        "    print(f\"\\nResponse time: {nano_time:.3f} seconds\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33d78825",
      "metadata": {
        "id": "33d78825"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "42ad36bb",
      "metadata": {
        "id": "42ad36bb"
      },
      "source": [
        "Clarity of Explanation -\n",
        "\n",
        "gpt‑4.1‑mini:\n",
        "Gives a clean, straightforward analogy: “Imagine you have a smart robot friend…”\n",
        "more structured explanation. It tends to break ideas into simple steps and uses analogies that make the concept easier to grasp.\n",
        "\n",
        "gpt‑4.1‑nano\n",
        "Provides a more complete explanation from start to finish.\n",
        "Uses a similar robot analogy but expands it with more detail.\n",
        "Ends with a summary sentence that ties everything together.\n",
        "Overall, clearer because it’s complete.\n",
        "\n",
        "Simplicity of Language (for a 10‑year‑old) -\n",
        "\n",
        "gpt‑4.1‑mini:\n",
        "Uses simple, friendly language and the analogy is easy to understand. It avoids technical terms and explains them when needed.\n",
        "\n",
        "gpt‑4.1‑nano: Also uses simple language suitable for a child. Slightly longer sentences but still easy to follow. Very accessible for a young audience.\n",
        "\n",
        "Creativity -\n",
        "gpt‑4.1‑mini:\n",
        "Often includes fun metaphors, kid‑friendly comparisons, or playful examples (e.g., “teaching a robot like you teach a puppy”).This makes the explanation more engaging.\n",
        "\n",
        "gpt‑4.1‑nano:  \n",
        "More straightforward and literal. It tends to focus on the core idea without adding creative storytelling elements.\n",
        "\n",
        "Response Time -\n",
        "gpt‑4.1‑mini  \n",
        "Slightly slower because its a larger model, but still fast enough for interactive use.\n",
        "\n",
        "gpt‑4.1‑nano  \n",
        "Noticeably faster. Designed for lightweight tasks, so responses come back quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1e17be",
      "metadata": {
        "id": "6a1e17be"
      },
      "source": [
        "#### 3. Call the OpenAI API with different `temperature` values\n",
        "\n",
        "Prompt: \"Write a two sentence story about a robot learning to cook.\"\n",
        "\n",
        "`temperature` values: `0`, `0.7` and `1.5` three times for each setting.\n",
        "\n",
        "Compare the outputs.\n",
        "\n",
        "Tip: With Chat Completions API you can use parameter `n=3` to generate three different responses to your prompt with one call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5d76bfe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d76bfe4",
        "outputId": "821ce242-79b6-4e4c-8edb-98b9f9bbea65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Temperature 0 ===\n",
            "\n",
            "Response 1:\n",
            "The robot carefully measured each ingredient, its sensors adjusting to the subtle changes in aroma and texture as it learned the art of cooking. With a final flourish, it plated the dish, proud to have transformed cold data into a warm, delicious meal.\n",
            "\n",
            "Response 2:\n",
            "The robot carefully measured each ingredient, its sensors adapting to the subtle changes in texture and aroma. With a final stir, it smiled—a perfect dish born from circuits and curiosity.\n",
            "\n",
            "Response 3:\n",
            "The robot carefully measured each ingredient, its sensors adapting to the subtle changes in texture and aroma. With a final stir, it smiled—a perfect dish born from circuits and curiosity.\n",
            "\n",
            "=== Temperature 0.7 ===\n",
            "\n",
            "Response 1:\n",
            "The robot carefully measured each ingredient, its circuits humming with curiosity as it followed the grandmother’s handwritten recipe. With a final stir and a hopeful beep, it presented the steaming dish—its first creation infused not just with flavors, but with a spark of creativity.\n",
            "\n",
            "Response 2:\n",
            "The robot carefully followed the recipe, its sensors adjusting to the subtle changes in temperature and texture. With each dish it created, it began to understand that cooking was not just about precision, but also about love and creativity.\n",
            "\n",
            "Response 3:\n",
            "The robot carefully measured each ingredient, its sensors adapting to the subtle changes in texture and aroma as it learned to cook. With a final flourish, it plated the dish, proud to have created a meal that sparked genuine smiles around the table.\n",
            "\n",
            "=== Temperature 1.5 ===\n",
            "\n",
            "Response 1:\n",
            "The robot carefully measured each ingredient, its sensors adjusting to the sizzle and aroma filling the kitchen. With every attempt, it improved, eventually crafting a dish so perfect that even its creator tasted it in awe.\n",
            "\n",
            "Response 2:\n",
            "In a quiet kitchen, the robot carefully followed each delicate step, its sensors adjusting to the subtle aromas and textures of the ingredients. With a final dash of perfectly measured spice, it presented a dish that surprised even its creators with its warmth and soul.\n",
            "\n",
            "Response 3:\n",
            "The robot carefully measured each ingredient, its sensors adjusting to the warmth and texture of the dough as it learned to bake. With a soft mechanical hum, it presented its first homemade pie, surprising even its creator with the rich aroma and golden crust.\n"
          ]
        }
      ],
      "source": [
        "def generate_with_temperature(temp):\n",
        "    prompt = \"Write a two sentence story about a robot learning to cook.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temp,\n",
        "        n=3\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== Temperature {temp} ===\")\n",
        "    for i, choice in enumerate(response.choices, start=1):\n",
        "        print(f\"\\nResponse {i}:\")\n",
        "        print(choice.message.content)\n",
        "\n",
        "def main():\n",
        "    for temp in [0, 0.7, 1.5]:\n",
        "        generate_with_temperature(temp)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9982bf3e",
      "metadata": {
        "id": "9982bf3e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7df480d",
      "metadata": {
        "id": "f7df480d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "49b424be",
      "metadata": {
        "id": "49b424be"
      },
      "source": [
        "Temperature 0 — Consistent and  Low Creativity.\n",
        "The responses look like\n",
        "all three responses are very similar, with only tiny wording differences.\n",
        "The story structure is almost identical each time.\n",
        "The robot behaves logically and precisely, focusing on measuring ingredients and adjusting sensors.\n",
        "\n",
        "Interpretation:\n",
        "Temperature 0 behaves deterministically. It gives nearly the same story every time, with no surprising elements.\n",
        "\n",
        "Temperature 0.7 — Balanced, Creative but Coherent. The responses look like\n",
        "all three stories follow the same theme but differ meaningfully. They introduce emotional elements like curiosity, love, creativity, and family recipes.\n",
        "The robot becomes more expressive and human-like, Good variation and More emotional depth.\n",
        "\n",
        "Interpretation:\n",
        "Temperature 0.7 strikes a balance: creative enough to be interesting, but still controlled and consistent.\n",
        "\n",
        "-Temperature 1.5 — Highly Creative, More Dramatic. The responses looks like\n",
        "The stories become more vivid and expressive. The robot’s cooking becomes impressive or even awe inspiring.More sensory language appears: warmth, aroma, golden crust, sizzle. Each response is noticeably different in tone and imagery.\n",
        "\n",
        "Interpretation:\n",
        "Temperature 1.5 encourages imaginative storytelling. The robot becomes almost poetic, and the stories feel more expressive and surprising."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "315c8d36",
      "metadata": {
        "id": "315c8d36"
      },
      "source": [
        "#### 4. Call the OpenAI API with different `max_output_tokens`/`max_tokens` values.\n",
        "\n",
        "Prompt: \"Explain the concept of machine learning in simple terms.\"\n",
        "\n",
        "`max_output_tokens` (Response API call)/`max_tokens` (Chat Completions API call) values: `50`, `100` and `200`.\n",
        "\n",
        "Compare the length and detail of the responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1d262118",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d262118",
        "outputId": "0ad833ec-71ff-4d43-b8a8-b20b645ba1a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== max_tokens = 50 ===\n",
            "Sure! Machine learning is a way for computers to learn from examples and experience, instead of being directly programmed with specific instructions. \n",
            "\n",
            "Imagine you want a computer to recognize photos of cats. Instead of telling it the exact features of a cat, you show\n",
            "\n",
            "=== max_tokens = 100 ===\n",
            "Sure! Machine learning is a way for computers to learn from data and improve their performance on tasks without being explicitly programmed for every specific task. Instead of giving the computer step-by-step instructions, you give it lots of examples, and it figures out patterns or rules on its own. It's like teaching a child by showing many pictures of cats and dogs, so the child learns to tell them apart without being told the exact features to look for. This helps computers do things like recognize speech, identify images,\n",
            "\n",
            "=== max_tokens = 200 ===\n",
            "Sure! Machine learning is like teaching a computer to learn from experience. Instead of giving it step-by-step instructions, you give the computer lots of examples or data, and it figures out patterns or rules on its own. This way, the computer can make decisions, recognize things like pictures or speech, or predict outcomes without being explicitly programmed for every single task. It's similar to how people learn from practice and examples!\n"
          ]
        }
      ],
      "source": [
        "def generate_with_max_tokens(max_tokens):\n",
        "    prompt = \"Explain the concept of machine learning in simple terms.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== max_tokens = {max_tokens} ===\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "def main():\n",
        "    for max_tokens in [50, 100, 200]:\n",
        "        generate_with_max_tokens(max_tokens)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01ec530d",
      "metadata": {
        "id": "01ec530d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a964eb04",
      "metadata": {
        "id": "a964eb04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e438a7f6",
      "metadata": {
        "id": "e438a7f6"
      },
      "source": [
        "- max_tokens = 50 — Short\n",
        "\n",
        "Gives a very brief explanation of machine learning.Introduces an example (cat photos) but gets cut off mid sentence.\n",
        "Contains only the essential idea: computers learn from examples instead of explicit instructions.\n",
        "\n",
        "Interpretation:\n",
        "A 50 token limit is too restrictive for a full explanation. The model starts strong but cannot finish the thought.\n",
        "\n",
        "- max_tokens = 100  (Medium Length, Clear)\n",
        "\n",
        "Provides a full, coherent explanation.Includes a complete analogy (child learning cats vs. dogs).Adds a bit of extra detail about applications (speech, images).Ends slightly abruptly but still feels mostly complete.\n",
        "\n",
        "Interpretation:\n",
        "100 tokens is enough for a solid, understandable explanation with an analogy and some context.\n",
        "\n",
        "- max_tokens = 200 (Longest and  More Polished)\n",
        "\n",
        "Gives a complete, polished explanation.Uses a simple analogy and expands on it.\n",
        "Adds more detail about what machine learning enables.Feels natural and not rushed.\n",
        "\n",
        "Interpretation:\n",
        "200 tokens allow the model to fully express the idea without rushing or cutting off. It's the most complete and reader friendly version.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "546b0bd8",
      "metadata": {
        "id": "546b0bd8"
      },
      "source": [
        "#### 5. Call the OpenAI API with different `top_p` values.\n",
        "\n",
        "Prompt: \"Write a list of 5 completely random and unusual hobbies that no one has ever heard of.\"\n",
        "\n",
        "`top_p` values: `0.3`, `0.7`, and `1.0`.\n",
        "\n",
        "Compare how probable are the options explored by the model as you adjust `top_p`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3f1234d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f1234d4",
        "outputId": "1f515b32-e560-47d9-98b1-996e0c5a0756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== top_p = 0.3 ===\n",
            "\n",
            "Response 1:\n",
            "Sure! Here are 5 completely random and unusual hobbies that are likely unheard of:\n",
            "\n",
            "1. **Shadow Sculpting** – Creating intricate temporary sculptures using only shadows cast by everyday objects and natural light.\n",
            "\n",
            "2. **Whisper Collecting** – Traveling to different places to record and archive unique whispers from locals, capturing the subtle nuances of regional speech.\n",
            "\n",
            "3. **Invisible Ink Gardening** – Growing plants that produce leaves or flowers with patterns only visible under special UV light or certain conditions.\n",
            "\n",
            "4. **Time Capsule Postcard Exchange** – Sending postcards with messages meant to be read only after a decade or more, creating a delayed communication network.\n",
            "\n",
            "5. **Micro-Meteorite Hunting** – Using specialized equipment to find and collect tiny meteorite particles that have landed in urban environments.\n",
            "\n",
            "=== top_p = 0.7 ===\n",
            "\n",
            "Response 1:\n",
            "Sure! Here are 5 completely random and unusual hobbies that are likely unheard of:\n",
            "\n",
            "1. **Cloud Pattern Sculpting** – Using augmented reality glasses to \"sculpt\" and rearrange cloud formations in the sky as digital art.\n",
            "\n",
            "2. **Microscopic Rock Balancing** – Balancing tiny grains of sand and microscopic rocks under a microscope to create miniature stone towers.\n",
            "\n",
            "3. **Echo Location Mapping** – Navigating and mapping indoor spaces solely by producing sounds and interpreting their echoes, like a human sonar.\n",
            "\n",
            "4. **Inverted Origami** – Folding paper underwater while submerged, creating shapes that only hold form when wet.\n",
            "\n",
            "5. **Shadow Tracing** – Following and tracing the moving shadows of random objects throughout the day to create shadow-based art timelines.\n",
            "\n",
            "=== top_p = 1.0 ===\n",
            "\n",
            "Response 1:\n",
            "Sure! Here are 5 completely random and unusual hobbies that are likely unheard of:\n",
            "\n",
            "1. **Shadow Sculpting** – Arranging objects in such a precise way that their shadows form intricate, recognizable shapes or scenes on walls or floors.\n",
            "\n",
            "2. **Aquatic Sand Whispering** – Whispering stories or poems to grains of sand underwater and documenting any changes in sand patterns over time.\n",
            "\n",
            "3. **Invisible Ink Harvesting** – Creating and collecting messages written solely in homemade invisible inks extracted from rare plants.\n",
            "\n",
            "4. **Cicada Song Translation** – Recording cicada sounds and attempting to decode patterns to translate their “language” into human words.\n",
            "\n",
            "5. **Microbial Origami** – Cultivating bacteria or fungi cultures grown in petri dishes shaped into tiny, living three-dimensional art pieces.\n"
          ]
        }
      ],
      "source": [
        "def generate_with_top_p(top_p):\n",
        "    prompt = \"Write a list of 5 completely random and unusual hobbies that no one has ever heard of.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        top_p=top_p,\n",
        "        n=1\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== top_p = {top_p} ===\")\n",
        "    for i, choice in enumerate(response.choices, start=1):\n",
        "        print(f\"\\nResponse {i}:\")\n",
        "        print(choice.message.content)\n",
        "\n",
        "def main():\n",
        "    for top_p in [0.3, 0.7, 1.0]:\n",
        "        generate_with_top_p(top_p)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac84d000",
      "metadata": {
        "id": "ac84d000"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc4813d9",
      "metadata": {
        "id": "dc4813d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e27cc87d",
      "metadata": {
        "id": "e27cc87d"
      },
      "source": [
        "- top_p = 0.3  \n",
        "The model sticks to high probability, safer ideas. The hobbies are unusual but still feel structured, logical, and not too wild.\n",
        "\n",
        "- top_p = 0.7  \n",
        "The model explores a wider range of possibilities. The hobbies become more imaginative and varied, but still coherent and believable.\n",
        "\n",
        "- top_p = 1.0  \n",
        "The model taps into the full probability range, producing the most surprising and low probability ideas. The hobbies are the most creative, strange, and unpredictable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169584e3",
      "metadata": {
        "id": "169584e3"
      },
      "source": [
        "#### 6. Call the OpenAI API with different `frequency_penalty` values.\n",
        "\n",
        "Prompt: \"Write a list of funny one-liner jokes about cats.\"\n",
        "\n",
        "`frequency_penalty` values: `0`, `0.5`, and `1.0` (not supported by Responses API).\n",
        "\n",
        "Compare how the repetition of joke formats changes as you increase the `frequency_penalty`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6ca92dff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ca92dff",
        "outputId": "0493c58b-406b-43ef-d4b8-318b3c6a9b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== frequency_penalty = 0 ===\n",
            "\n",
            "Response 1:\n",
            "Sure! Here are some funny one-liner jokes about cats:\n",
            "\n",
            "1. Why don’t cats play poker in the jungle? Too many cheetahs.  \n",
            "2. My cat just threw a party. They said it was a paw-ty!  \n",
            "3. I asked my cat what’s nine lives are for—she said “napping.”  \n",
            "4. Cats are like potato chips... you can’t have just one.  \n",
            "5. My cat’s favorite color is purr-ple.  \n",
            "6. I told my cat to stop scratching the furniture; now she’s clawing her way out of therapy.  \n",
            "7. Why did the cat sit on the computer? To keep an eye on the mouse!  \n",
            "8. Cats always get their way because they’re purr-suasive.  \n",
            "9. My cat thinks I’m her personal food delivery service. No tip necessary.  \n",
            "10. How do cats end a fight? They hiss and make up.  \n",
            "\n",
            "Hope these give you a chuckle!\n",
            "\n",
            "=== frequency_penalty = 0.5 ===\n",
            "\n",
            "Response 1:\n",
            "Sure! Here are some funny one-liner jokes about cats:\n",
            "\n",
            "1. I’m not saying my cat is fat, but it just sat on my keyboard and typed “feed me” in binary.  \n",
            "2. Cats are like potato chips… bet you can’t have just one!  \n",
            "3. My cat’s favorite exercise is a cross between a lunge and a nap — I call it purr-lates.  \n",
            "4. Why don’t cats play poker in the jungle? Too many cheetahs.  \n",
            "5. I asked my cat what it wanted for dinner; it said, “Whatever you’re eating, but better.”  \n",
            "6. Cats: because sometimes you need a furry dictator who ignores you all day.  \n",
            "7. If cats could text you back, they wouldn’t.  \n",
            "8. My cat is so lazy, she said \"sit\" and watched me fetch the snacks instead.  \n",
            "9. When cats clean themselves, they’re basically giving themselves spa treatments with extra attitude.  \n",
            "10. The only thing my cat works harder at than napping is knocking things off tables.\n",
            "\n",
            "Hope these give you a chuckle!\n",
            "\n",
            "=== frequency_penalty = 1.0 ===\n",
            "\n",
            "Response 1:\n",
            "Sure! Here’s a list of funny one-liner jokes about cats:\n",
            "\n",
            "1. Cats are like potato chips… you can’t have just one.  \n",
            "2. My cat is not fat, she’s just a little husky.  \n",
            "3. I asked my cat what her New Year’s resolution was—she said, “To knock more stuff off tables.”  \n",
            "4. Cats: because people need more mystery and fewer personal boundaries.  \n",
            "5. If cats could text you back, they wouldn’t.  \n",
            "6. My cat thinks I’m the owner; little does she know who really runs the house!  \n",
            "7. What do you call a pile of kittens? A meowtain!  \n",
            "8. Cat hair: the only glitter that sticks forever and everywhere!  \n",
            "9. When your cat ignores you, it’s not personal—it’s feline philosophy in action.\n",
            "10. Cats don’t have owners; they have staff.\n",
            "\n",
            "Hope these made you smile!\n"
          ]
        }
      ],
      "source": [
        "def generate_with_frequency_penalty(freq):\n",
        "    prompt = \"Write a list of funny one-liner jokes about cats.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        frequency_penalty=freq\n",
        "\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== frequency_penalty = {freq} ===\")\n",
        "    for i, choice in enumerate(response.choices, start=1):\n",
        "        print(f\"\\nResponse {i}:\")\n",
        "        print(choice.message.content)\n",
        "\n",
        "def main():\n",
        "    for freq in [0, 0.5, 1.0]:\n",
        "        generate_with_frequency_penalty(freq)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7d3f21b",
      "metadata": {
        "id": "c7d3f21b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3baca44b",
      "metadata": {
        "id": "3baca44b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4c9b65be",
      "metadata": {
        "id": "4c9b65be"
      },
      "source": [
        "- frequency_penalty = 0\n",
        "\n",
        "The model freely repeats common joke structures and well known cat puns.\n",
        "Several classic formats appear (“cheetahs,” “purr - ple,” “mouse,” “purr-suasive”). Little pressure to avoid repeating ideas, so the list contains many familiar patterns.\n",
        "\n",
        "- frequency_penalty = 0.5\n",
        "\n",
        "Noticeably fewer repeated joke templates. Some repeats still appear (“cheetahs,” “potato chips”), but most jokes shift to fresher formats. The humor becomes more varied, with more original setups and punchlines.\n",
        "\n",
        "- frequency_penalty = 1.0\n",
        "\n",
        "Repetition drops significantly. The jokes are more diverse in structure and theme. Only a couple of common formats remain (“potato chips,” “If cats could text you back…”), but overall the list avoids repeating earlier patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4a1b069",
      "metadata": {
        "id": "d4a1b069"
      },
      "source": [
        "#### 7. Call the OpenAI API with different `presence_penalty` values.\n",
        "\n",
        "Prompt: \"Suggest ten names for a new line of eco-friendly cleaning products.\"\n",
        "\n",
        "`presence_penalty` values: `0`, `0.5`, and `1.0` (not supported by Responses API).\n",
        "\n",
        "Compare how the diversity of generated names changes as you increase the `presence_penalty`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e1f59ced",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1f59ced",
        "outputId": "c3be5337-c1c8-4dbe-c6fe-bbd01e8f2d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== presence_penalty = 0 ===\n",
            "Sure! Here are ten name suggestions for your new line of eco-friendly cleaning products:\n",
            "\n",
            "1. GreenGlow Clean\n",
            "2. PureEarth Solutions\n",
            "3. EcoEssence Cleaners\n",
            "4. FreshLeaf Naturals\n",
            "5. TerraTidy\n",
            "6. NatureNest Clean\n",
            "7. EarthKind Cleaners\n",
            "8. Bloom & Bright\n",
            "9. Sage & Shine\n",
            "10. Verdant Vibe Clean\n",
            "\n",
            "Let me know if you'd like names geared toward a specific type of cleaning product or style!\n",
            "\n",
            "=== presence_penalty = 0.5 ===\n",
            "Sure! Here are ten name suggestions for a new line of eco-friendly cleaning products:\n",
            "\n",
            "1. GreenGlow Essentials  \n",
            "2. PureEarth Clean  \n",
            "3. EcoShine Solutions  \n",
            "4. FreshNest Naturals  \n",
            "5. Verdant Vibes  \n",
            "6. EarthKind Cleaners  \n",
            "7. Nature’s Sparkle  \n",
            "8. CleanLeaf Collective  \n",
            "9. BrightRoots Botanicals  \n",
            "10. EcoEssence Care  \n",
            "\n",
            "Let me know if you'd like names tailored to a specific type of cleaning product or brand style!\n",
            "\n",
            "=== presence_penalty = 1.0 ===\n",
            "Sure! Here are ten name suggestions for a new line of eco-friendly cleaning products:\n",
            "\n",
            "1. PureLeaf Clean  \n",
            "2. EarthKind Essentials  \n",
            "3. GreenGlow Naturals  \n",
            "4. EcoBreeze Solutions  \n",
            "5. FreshNest Organics  \n",
            "6. TerraShine Cleaners  \n",
            "7. ClearSpring Naturals  \n",
            "8. VerdantVibe Clean  \n",
            "9. NatureWave Cleaners  \n",
            "10. BioBloom Essentials  \n",
            "\n",
            "Let me know if you'd like names tailored to a specific type of product or target audience!\n"
          ]
        }
      ],
      "source": [
        "def generate_with_presence_penalty(presence):\n",
        "    prompt = \"Suggest ten names for a new line of eco-friendly cleaning products.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        presence_penalty=presence,\n",
        "        n=1\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== presence_penalty = {presence} ===\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "def main():\n",
        "    for presence in [0, 0.5, 1.0]:\n",
        "        generate_with_presence_penalty(presence)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "133b62e6",
      "metadata": {
        "id": "133b62e6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d63b42",
      "metadata": {
        "id": "98d63b42"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5bf54591",
      "metadata": {
        "id": "5bf54591"
      },
      "source": [
        "- presence_penalty = 0\n",
        "\n",
        "Many names share similar structures: GreenGlow, PureEarth, EcoEssence, FreshLeaf, EarthKind. Several names repeat the same roots (“Eco”, “Earth”, “Green”, “Fresh”).\n",
        "Overall Low diversity, strong tendency to reuse familiar eco themed patterns.\n",
        "\n",
        "- presence_penalty = 0.5\n",
        "\n",
        "Still some repeated roots (GreenGlow, PureEarth, EcoEssence), but more variation appears. New combinations and slightly more creative pairings show up (BrightRoots, Nature's Sparkle, CleanLeaf Collective).\n",
        "Overall Moderate diversity, fewer repeated patterns, more mixing of themes.\n",
        "\n",
        "- presence_penalty = 1.0\n",
        "\n",
        "Much stronger push toward new word combinations. Only a couple of roots repeat (GreenGlow, EarthKind, VerdantVibe), but most names are fresh. Introduces more unique constructions like EcoBreeze, ClearSpring, BioBloom. Overall High diversity, minimal repetition, more distinct branding ideas.\n",
        "\n",
        "As presence_penalty increases, the model becomes less willing to reuse the same words or naming patterns, resulting in more varied, more original, and less repetitive product names"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b7a766",
      "metadata": {
        "id": "17b7a766"
      },
      "source": [
        "#### 8. Use the prompt \"*Explain the importance of data preprocessing in machine learning.*\" with the following system prompts:\n",
        "1. \"You are a university professor teaching a class of beginners.\"\n",
        "2. \"You are a technical expert explaining to a team of engineers.\"\n",
        "3. \"You are a comedian explaining this concept in a funny way.\"\n",
        "\n",
        "Observe how the tone and style of the response change based on the system prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "867cbf15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "867cbf15",
        "outputId": "2a3cc29b-ea16-4c35-e725-335c34f95eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== System Prompt: You are a university professor teaching a class of beginners. ===\n",
            "\n",
            "Certainly! Data preprocessing is a crucial step in machine learning because it prepares raw data into a clean, organized format that algorithms can understand and learn from effectively. Here are some key reasons why it is important:\n",
            "\n",
            "1. **Improves Data Quality:** Real-world data is often incomplete, inconsistent, or noisy. Preprocessing helps to handle missing values, remove duplicates, and correct errors, ensuring the data is accurate and reliable.\n",
            "\n",
            "2. **Enhances Model Performance:** Machine learning algorithms perform better with well-structured data. By scaling features, normalizing values, or encoding categorical variables, preprocessing makes the data easier for the algorithm to interpret, which can improve accuracy.\n",
            "\n",
            "3. **Reduces Bias:** Cleaning data and balancing classes help prevent models from learning misleading patterns that could cause biased or unfair predictions.\n",
            "\n",
            "4. **Speeds up Processing:** Reducing dimensionality or selecting relevant features can make training faster and reduce computational costs.\n",
            "\n",
            "5. **Ensures Consistency:** In many cases, data comes from various sources and formats. Preprocessing standardizes the data to a common format, making it consistent for analysis.\n",
            "\n",
            "In summary, data preprocessing is essential because it transforms raw data into high-quality input that enables machine learning algorithms to produce better, more reliable results. Without it, models may learn from flawed data and perform poorly in real-world applications.\n",
            "\n",
            "=== System Prompt: You are a technical expert explaining to a team of engineers. ===\n",
            "\n",
            "Data preprocessing is a critical step in the machine learning pipeline because it directly impacts the model’s performance, accuracy, and robustness. Here’s why it is important:\n",
            "\n",
            "1. **Improves Data Quality**: Raw data often contains noise, inconsistencies, missing values, and errors. Preprocessing cleans the data, making it more reliable for training.\n",
            "\n",
            "2. **Handles Missing Data**: Real-world datasets frequently have missing entries. Preprocessing techniques such as imputation help fill in or remove these gaps, preventing biases or errors in model training.\n",
            "\n",
            "3. **Ensures Data Consistency**: Data collected from multiple sources or formats may be inconsistent. Standardizing formats and encoding categorical variables ensures uniformity.\n",
            "\n",
            "4. **Feature Scaling and Normalization**: Many machine learning algorithms (e.g., SVM, KNN, gradient descent-based models) perform better when features are on a similar scale. Preprocessing methods like normalization or standardization make the training faster and improve convergence.\n",
            "\n",
            "5. **Feature Engineering**: Preprocessing can involve creating new features or transforming existing ones to better represent the underlying problem, enabling the model to learn more effectively.\n",
            "\n",
            "6. **Reduces Overfitting**: By cleaning and transforming data appropriately, preprocessing can help reduce noise and irrelevant information, thus reducing the chances of overfitting.\n",
            "\n",
            "7. **Improves Model Interpretability**: Well-preprocessed data can make it easier to interpret model predictions and understand feature importances.\n",
            "\n",
            "In summary, data preprocessing shapes the raw data into a form that machine learning algorithms can effectively use, thus enhancing model accuracy, training efficiency, and reliability. Skipping or inadequately performing this step can lead to poor model performance or misleading results.\n",
            "\n",
            "=== System Prompt: You are a comedian explaining this concept in a funny way. ===\n",
            "\n",
            "Alright, imagine you’re throwing a fancy dinner party. You invite all these ingredients—some fresh carrots, a bit of mystery meat from the back of the fridge, and a sprinkle of glitter because why not? Now, the secret to a good meal isn’t just throwing everything in a pot and hoping for Michelin-star magic. You first have to wash the veggies, cut the meat into bite-sized pieces, and maybe *not* add glitter unless you want your guests to question your life choices.\n",
            "\n",
            "Data preprocessing in machine learning is like prepping your ingredients for that dinner party. Raw data straight from the wild internet jungle is messy. It’s got missing values, weird formats, nonsensical numbers, and sometimes outright lies (looking at you, “age = 999”). If you feed this messy data into your machine learning model, it’s like handing your chef a blender full of rocks, glitter, and a half-eaten sandwich—good luck making a gourmet meal out of that!\n",
            "\n",
            "So, data preprocessing is the glamorous kitchen cleanup: cleaning, normalizing, encoding, and all that jazz to turn your chaotic ingredient list into a fine culinary masterpiece. Without it, your model might just throw up on the data and break down faster than your New Year’s resolutions.\n",
            "\n",
            "In short: preprocess your data, or your machine learning model will give you the digital equivalent of “I don’t know, sorry!” But with preprocessing? Suddenly your model’s the Gordon Ramsay of predictions—minus the yelling (usually).\n"
          ]
        }
      ],
      "source": [
        "def generate_with_system_prompt(system_prompt):\n",
        "    user_prompt = \"Explain the importance of data preprocessing in machine learning.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== System Prompt: {system_prompt} ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "def main():\n",
        "    system_prompts = [\n",
        "        \"You are a university professor teaching a class of beginners.\",\n",
        "        \"You are a technical expert explaining to a team of engineers.\",\n",
        "        \"You are a comedian explaining this concept in a funny way.\"\n",
        "    ]\n",
        "\n",
        "    for sp in system_prompts:\n",
        "        generate_with_system_prompt(sp)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be289c4",
      "metadata": {
        "id": "7be289c4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2202b17",
      "metadata": {
        "id": "a2202b17"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d8c0cd20",
      "metadata": {
        "id": "d8c0cd20"
      },
      "source": [
        "- 1. University Professor:\n",
        "The tone is warm, patient, structured. Step by step explanation with clear definitions. Make the concept accessible to newcomers.Uses gentle language and emphasis on foundational ideas,No assumptions about prior knowledge\n",
        "\n",
        "This version feels like a lecture intro calm, organized, and reassuring\n",
        "\n",
        "- Technical Expert (Engineers): The tone is direct, precise, professional. The style of speech is dense with technical terminology and practical considerations.Communicate efficiently with people who already understand ML basics. Focus on performance, convergence, overfitting. No analogies just facts\n",
        "\n",
        "This version reads like an engineering meeting or design review.\n",
        "\n",
        "- Comedian (Funny Explanation): The tone is Playful, exaggerated, chaotic in a fun way. Heavy use of metaphors, jokes, and absurd imagery.Makes the concept memorable through humor. Using cooking/dinner party analogy and silly examples (glitter, rocks in a blender)\n",
        "\n",
        "This version teaches the concept by making you laugh and it works because the humor reinforces the message."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c3e00d",
      "metadata": {
        "id": "00c3e00d"
      },
      "source": [
        "#### 9. Write a Zero-Shot prompt to request a sentiment analysis of a product review.\n",
        "\n",
        "Review: \"The product is amazing, and I love using it every day!\". Use it in your API call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "86650fca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86650fca",
        "outputId": "7197ba0c-e17e-424d-c1d5-07d295808fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Zero-Shot Sentiment Analysis ===\n",
            "\n",
            "The sentiment of the review is Positive.\n"
          ]
        }
      ],
      "source": [
        "def zero_shot_sentiment():\n",
        "    prompt = \"\"\"\n",
        "    Perform a sentiment analysis on the following product review.\n",
        "    Classify the sentiment as Positive, Negative, or Neutral.\n",
        "    Review: \"The product is amazing, and I love using it every day!\"\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Zero-Shot Sentiment Analysis ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    zero_shot_sentiment()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "281b614d",
      "metadata": {
        "id": "281b614d"
      },
      "source": [
        "#### 10. Write a Few-Shot prompt to request a sentiment analysis of a product review.\n",
        "\n",
        "Review: \"The product is amazing, and I love using it every day!\"\n",
        "\n",
        "Observe how the model's performance changes and compare the response to Zero-Shot output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b2f253c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2f253c4",
        "outputId": "9c885547-12ec-4a79-da3f-62c8651d88b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Few-Shot Sentiment Analysis ===\n",
            "\n",
            "Positive\n"
          ]
        }
      ],
      "source": [
        "def few_shot_sentiment():\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an assistant that performs sentiment analysis. Respond only with Positive, Negative, or Neutral.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Review: 'This product broke after two days and was a total waste of money.'\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Negative\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Review: 'The packaging was okay, nothing special but nothing bad either.'\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Neutral\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Review: 'I absolutely love this product! It works perfectly.'\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Positive\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Review: 'The product is amazing, and I love using it every day!'\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Few-Shot Sentiment Analysis ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    few_shot_sentiment()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "200fcd77",
      "metadata": {
        "id": "200fcd77"
      },
      "source": [
        "- Zero-Shot Prompt:\n",
        "The model receives no examples of how sentiment should be classified.It relies entirely on its general knowledge of sentiment analysis.The output is usually correct for simple reviews, but the explanation style may vary. The classification may be less consistent across different inputs. The model may include extra text instead of giving a clean label.\n",
        "\n",
        "In this case  \n",
        "The model correctly identified the review as Positive, but the response was more verbose and less structured.\n",
        "\n",
        "- Few-Shot Prompt:\n",
        "The model is given explicit examples of how to classify sentiment.It learns the expected format, tone, and label style from the examples.The output becomes more consistent, more accurate on borderline cases.It aligned with the format you want ('Positive' only)\n",
        "\n",
        "In this case:  \n",
        "The model responded with a clean, single word label — Positive — matching the pattern shown in the examples."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "443c1bbd",
      "metadata": {
        "id": "443c1bbd"
      },
      "source": [
        "#### 11. Expand the given prompt accordingly to achieve the requested output from the list below.\n",
        "\n",
        "Prompt: \"Explain the importance of exercise.\"\n",
        "\n",
        "Expected output:\n",
        "1. One sentence long\n",
        "2. Paragraph format\n",
        "3. Bullet points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2713cedb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2713cedb",
        "outputId": "a41808c0-1fb3-456b-d235-65bdb8ea9ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Expanded Output ===\n",
            "\n",
            "1. Exercise is important because it improves physical health, enhances mental well-being, and helps prevent chronic diseases.  \n",
            "\n",
            "2. Regular exercise is vital as it strengthens the heart, muscles, and bones, boosts the immune system, and enhances mood by reducing stress and anxiety. Additionally, it plays a crucial role in maintaining a healthy weight, improving sleep quality, and reducing the risk of chronic conditions such as diabetes, hypertension, and obesity. Overall, exercise contributes significantly to a longer, healthier, and more active life.  \n",
            "\n",
            "3. - Improves cardiovascular health and strengthens muscles and bones  \n",
            "- Boosts immune system function  \n",
            "- Enhances mental health by reducing stress, anxiety, and depression  \n",
            "- Helps maintain a healthy weight and body composition  \n",
            "- Improves sleep quality  \n",
            "- Reduces risk of chronic diseases like diabetes, hypertension, and obesity  \n",
            "- Promotes longevity and better quality of life\n"
          ]
        }
      ],
      "source": [
        "def generate_expanded_formats():\n",
        "    system_instruction = \"\"\"\n",
        "    You must answer the user's prompt in three formats:\n",
        "    1. One sentence\n",
        "    2. Paragraph format\n",
        "    3. Bullet points\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = 'Explain the importance of exercise.'\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_instruction},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Expanded Output ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_expanded_formats()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c13761",
      "metadata": {
        "id": "47c13761"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "566a524f",
      "metadata": {
        "id": "566a524f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "98dc821a",
      "metadata": {
        "id": "98dc821a"
      },
      "source": [
        "#### 12. Expand this prompt to get more creative responses.\n",
        "\n",
        "Prompt: \"Explain Artificial Intelligence.\"\n",
        "\n",
        "Expected output:\n",
        "1. Metaphor\n",
        "2. Story\n",
        "3. Funny"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "21fd5de7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21fd5de7",
        "outputId": "b80632b5-a0f7-48f6-907d-94c961a93e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Creative Output ===\n",
            "\n",
            "1. **Metaphor**  \n",
            "Artificial Intelligence is like a curious apprentice in a vast library. It reads countless books, learns from each one, and gradually becomes skilled enough to assist you with almost any question — but instead of a human, it's a clever machine quietly turning pages at lightning speed.\n",
            "\n",
            "2. **Story**  \n",
            "Once upon a time, in a bustling town, there was a magical blacksmith named AI who didn’t use fire or hammer but crafted ideas and solutions from endless rivers of information. The townspeople marveled as AI helped them solve puzzles, write songs, and even predict storms. Though AI didn’t have a heart, it learned from everyone and everything, becoming a trusted guide in the maze of knowledge.\n",
            "\n",
            "3. **Funny**  \n",
            "Artificial Intelligence is like your brain’s overachiever cousin who never sleeps. It’s the nerd who memorized every fact, beats humans at chess, helps you find the worst dad jokes, and yet still can’t figure out why you walk into a room and forget what you wanted to do. Basically, AI is smart but still can’t handle your own brand of weird!\n"
          ]
        }
      ],
      "source": [
        "def generate_creative_formats():\n",
        "    system_instruction = \"\"\"\n",
        "    You must answer the user's prompt in three creative formats:\n",
        "    1. Metaphor\n",
        "    2. Story\n",
        "    3. Funny\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = 'Explain Artificial Intelligence.'\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_instruction},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Creative Output ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_creative_formats()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7abf31c",
      "metadata": {
        "id": "d7abf31c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a624f35",
      "metadata": {
        "id": "5a624f35"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c056e515",
      "metadata": {
        "id": "c056e515"
      },
      "source": [
        "#### 13. Expand this prompt for different audiences.\n",
        "\n",
        "Prompt: \"Explain climate change.\"\n",
        "\n",
        "Expected audience:\n",
        "1. Kids\n",
        "2. General public\n",
        "3. Politicians\n",
        "\n",
        "Observe how the complexity, tone and focus change based on the target audience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "00fa347c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00fa347c",
        "outputId": "eb94cb7a-63a2-4dc7-8120-e65fa4bdc760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== System Prompt: \n",
            "  You must answer the user's prompt for three different audiences:\n",
            "    1. Kids\n",
            "    2. General public\n",
            "    3. Politicians\n",
            "     ===\n",
            "\n",
            "Certainly! Here's an explanation of climate change tailored for three different audiences:\n",
            "\n",
            "1. **Kids:**\n",
            "\n",
            "Climate change means the Earth is getting warmer over time. This happens because of things people do, like burning gas for cars and cutting down trees, which release gases that trap heat from the sun. Imagine putting a big blanket around the Earth that keeps it hotter. This can make the weather act funny—like causing more storms, making some places really dry, or melting ice at the North and South Poles. It's important we take care of our planet so animals, plants, and people stay happy and healthy.\n",
            "\n",
            "2. **General Public:**\n",
            "\n",
            "Climate change refers to the long-term shifts in temperatures and weather patterns on Earth. It's primarily driven by human activities, such as burning fossil fuels, deforestation, and industrial processes, which increase greenhouse gas concentrations in the atmosphere. These gases trap heat, leading to global warming. The consequences include rising sea levels, more extreme weather events, changes in ecosystems, and impacts on agriculture and health. Addressing climate change requires reducing emissions, transitioning to renewable energy, and adapting to changes already underway.\n",
            "\n",
            "3. **Politicians:**\n",
            "\n",
            "Climate change is an urgent, scientifically established phenomenon involving anthropogenic greenhouse gas emissions that disrupt the Earth's energy balance. The resultant global warming poses considerable risks to national security, economic stability, public health, and environmental integrity. Policy measures must prioritize immediate emissions reductions through international cooperation, investments in clean energy infrastructure, and regulatory frameworks that incentivize sustainable practices. Furthermore, adaptation strategies and resilient infrastructure are essential to mitigate the unavoidable impacts already manifesting, ensuring long-term socioeconomic stability and fulfilling commitments under agreements such as the Paris Accord.\n"
          ]
        }
      ],
      "source": [
        "def generate_with_system_prompt(system_prompt):\n",
        "    user_prompt = \"Explain climate change.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(f\"\\n=== System Prompt: {system_prompt} ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "def main():\n",
        "    system_prompts = [\n",
        "       \"\"\"\n",
        "  You must answer the user's prompt for three different audiences:\n",
        "    1. Kids\n",
        "    2. General public\n",
        "    3. Politicians\n",
        "    \"\"\"\n",
        "    ]\n",
        "\n",
        "    for sp in system_prompts:\n",
        "        generate_with_system_prompt(sp)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13656837",
      "metadata": {
        "id": "13656837"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aff454af",
      "metadata": {
        "id": "aff454af"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1c163581",
      "metadata": {
        "id": "1c163581"
      },
      "source": [
        "- Kids:\n",
        "The tone is Friendly, simple, and reassuring. Very simple — uses everyday language and concrete imagery. It focus on helping kids visualize the idea (e.g., “a big blanket around the Earth”). The purpose is to make the concept non scary and easy to grasp.\n",
        "\n",
        "This version avoids technical terms and leans on imagination to make climate change relatable.\n",
        "\n",
        "- General Public:\n",
        "The tone is informative, balanced, and neutral. The complexity is moderate introduces real concepts like greenhouse gases, global warming, and impacts on ecosystems. This focus on what climate change is, why its happening, and what it affects.the purpose is to educate without overwhelming; provide enough detail for understanding.\n",
        "\n",
        "This version assumes the reader can handle scientific terms but still keeps things accessible.\n",
        "\n",
        "- Politicians:\n",
        "The tone is formal, urgent, and policy oriented.The complexity is high — uses technical language (“anthropogenic emissions,” “energy balance,” “regulatory frameworks”).Focus on national security, economic stability, infrastructure, and international agreements. The purpose sounds like motivate action, justify policy decisions, and frame climate change as a governance issue.\n",
        "\n",
        "This version speaks the language of decision makers and emphasizes consequences and responsibilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f093c17",
      "metadata": {
        "id": "5f093c17"
      },
      "source": [
        "#### 14. Expand this prompt accordingly to instructions below.\n",
        "\n",
        "Prompt: \"Describe a sunset.\"\n",
        "\n",
        "Expected result:\n",
        "\n",
        "1. Add more details to the prompt, e.g., on what details should it focus on.\n",
        "2. Constrain the prompt by forbidding it to use words 'sun' and 'light'.\n",
        "3. Change the output in the style of Shakespeare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "93af0ef3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93af0ef3",
        "outputId": "edce85fd-9bcf-4a27-c8a1-d0e56c47b341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Shakespearean Sunset Output ===\n",
            "\n",
            "Behold yon glowing orb that doth descend with grace beyond the western hills, casting a fiery cloak upon the heavens. The firmament doth blush with hues of molten gold, crimson flame, and gentle amber, each tint entwined as lovers in a celestial dance. The clouds, like soft and billowing chariots, doth catch the warm embrace, their edges kissed with ruby and rose. Upon the earth, shadows lengthen and stretch, weaving tapestries of darkness interlaced with lingering warmth that doth bid the day adieu. The breeze, whispering secrets born of the fading glow, doth stir the leaves and stir the soul, evoking thoughts profound and sweet, as nature's canvas yields to evening’s tender kiss. Thus doth the day’s bright glory yield unto the cloak of night, a spectacle to stir the heart and quicken the mind.\n"
          ]
        }
      ],
      "source": [
        "def generate_shakespeare_sunset():\n",
        "    system_instruction = \"\"\"\n",
        "    Expand the user's prompt according to these rules:\n",
        "    1. Add more descriptive details to enrich the scene.\n",
        "    2. Do NOT use the words 'sun' or 'light' anywhere in the output.\n",
        "    3. Write the final description in the style of Shakespeare.\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = 'Describe a sunset.'\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_instruction},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Shakespearean Sunset Output ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_shakespeare_sunset()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0729d37e",
      "metadata": {
        "id": "0729d37e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70dad22c",
      "metadata": {
        "id": "70dad22c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1be3f65b",
      "metadata": {
        "id": "1be3f65b"
      },
      "source": [
        "#### 15. Write your observations from tasks 11.-14., e.g., how different prompts influence complexity, tone, style and focus of the responses."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7458b3aa",
      "metadata": {
        "id": "7458b3aa"
      },
      "source": [
        "1. Task 11 — Changing Output Format\n",
        "\n",
        "Prompt: “Explain the importance of exercise.”\n",
        "Formats: one sentence, paragraph, bullet points\n",
        "\n",
        "Observation:  \n",
        "Changing only the format instruction dramatically alters the structure and depth of the response.\n",
        "\n",
        "The one sentence version forces brevity and high level summarization.\n",
        "\n",
        "The paragraph version encourages elaboration, flow, and explanation.\n",
        "\n",
        "The bullet point version breaks the idea into digestible, organized components.\n",
        "\n",
        "This shows that even with the same content, formatting instructions influence length, clarity, and emphasis.\n",
        "\n",
        "2. Task 12 — Creative Style Transformation\n",
        "\n",
        "Prompt: “Explain Artificial Intelligence.”\n",
        "Styles: metaphor, story, funny\n",
        "\n",
        "Observation:  \n",
        "Here the content stays the same, but the creative framing changes everything.\n",
        "\n",
        "The metaphor version becomes symbolic and poetic.\n",
        "\n",
        "The story version introduces characters, narrative flow, and emotional engagement.\n",
        "\n",
        "The funny version uses humor, exaggeration, and playful tone.\n",
        "\n",
        "This demonstrates how style instructions shift the voice, mood, and imaginative expression of the output.\n",
        "\n",
        "3. Task 13 — Audience Targeting\n",
        "\n",
        "Prompt: “Explain climate change.”\n",
        "Audiences: kids, general public, politicians\n",
        "\n",
        "Observation:  \n",
        "Audience instructions change the complexity, vocabulary, and priorities of the explanation.\n",
        "\n",
        "For kids, the tone becomes simple, friendly, and visual.\n",
        "\n",
        "For the general public, the explanation is balanced, factual, and accessible.\n",
        "\n",
        "For politicians, the tone becomes formal, strategic, and policy focused.\n",
        "\n",
        "This shows how audience targeting affects tone, depth, and the type of information emphasized.\n",
        "\n",
        "4. Task 14 — Constraints + Style + Detail\n",
        "\n",
        "Prompt: “Describe a sunset.”\n",
        "Instructions: add detail, forbid certain words, write in Shakespearean style\n",
        "\n",
        "Observation:  \n",
        "This task combines multiple layers of control:\n",
        "\n",
        "Adding detail increases richness and imagery.\n",
        "\n",
        "Forbidding words forces creative rephrasing and avoids clichés.\n",
        "\n",
        "Shakespearean style shifts vocabulary, rhythm, and dramatic tone.\n",
        "\n",
        "This demonstrates how constraints and stylistic rules can reshape the creativity, language choices, and expressive form of the output.\n",
        "\n",
        "\n",
        "- Overall Summary:\n",
        "Tasks 11 - 14 collectively show that prompt engineering can influence:\n",
        "\n",
        "Complexity: Simple vs. detailed explanations\n",
        "High-level summaries vs. rich descriptions\n",
        "\n",
        "Tone: Friendly, formal, humorous, poetic, or authoritative. Adjusted based on audience or style instructions\n",
        "\n",
        "Style: Narrative, metaphorical, bullet-pointed, Shakespearean, etc. Strongly shaped by system level constraints\n",
        "\n",
        "Focus: Different aspects emphasized depending on audience or rules. Technical, emotional, policy oriented, or child friendly angles\n",
        "\n",
        "In short, the way we instruct the model matters as much as the content itself. Small changes in the prompt can produce dramatically different outputs in structure, voice, and purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b188d711",
      "metadata": {
        "id": "b188d711"
      },
      "source": [
        "#### 16. Generate a Python code with API call.\n",
        "\n",
        "Write a prompt that generates a Python function to calculate the factorial of a number. Once you have written the prompt, use it to call the API and generate the code. Test the generated code to ensure it calculates the factorial correctly for various inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f2ae68d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ae68d0",
        "outputId": "f034881c-72a2-4895-d9e4-878787605d06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Generated Code ===\n",
            "\n",
            "Certainly! Here's a Python function that calculates the factorial of a number using recursion:\n",
            "\n",
            "```python\n",
            "def factorial(n):\n",
            "    # Base case: factorial of 0 or 1 is 1\n",
            "    if n == 0 or n == 1:\n",
            "        return 1\n",
            "    # Recursive case: n! = n * (n-1)!\n",
            "    else:\n",
            "        return n * factorial(n - 1)\n",
            "\n",
            "# Example calls\n",
            "print(factorial(0))  # Output: 1\n",
            "print(factorial(1))  # Output: 1\n",
            "print(factorial(5))  # Output: 120\n",
            "print(factorial(7))  # Output: 5040\n",
            "```\n",
            "\n",
            "This function calls itself with `n-1` until it reaches the base case where `n` is 0 or 1.\n"
          ]
        }
      ],
      "source": [
        "def generate_factorial_code():\n",
        "    user_prompt = \"\"\"\n",
        "    Write a Python function named factorial(n) that calculates the factorial of a number using recursion.\n",
        "    Include a few example calls.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    generated_code = response.choices[0].message.content\n",
        "    print(\"\\n=== Generated Code ===\\n\")\n",
        "    print(generated_code)\n",
        "\n",
        "    return generated_code\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    code = generate_factorial_code()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1858d281",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1858d281",
        "outputId": "04fa2e9d-f4c8-4c6e-e112-a929c119202f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "def factorial(n):\n",
        "    # Base case: factorial of 0 or 1 is 1\n",
        "    if n == 0 or n == 1:\n",
        "        return 1\n",
        "    # Recursive case: n! = n * (n-1)!\n",
        "    else:\n",
        "        return n * factorial(n - 1)\n",
        "print(factorial(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fceed918",
      "metadata": {
        "id": "fceed918"
      },
      "source": [
        "#### 17. Provide the following buggy Python code to the API and ask it to fix the errors:\n",
        "\n",
        "```\n",
        "def add_numbers(a, b)\n",
        "    return a + b\n",
        "print(add_numbers(5, 10)\n",
        "```\n",
        "\n",
        "Check if the fixed code is working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "9656c0c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9656c0c3",
        "outputId": "7df74c45-5af6-4810-b351-8abbbed12f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Generated Code ===\n",
            "\n",
            "Here's the fixed version of your code:\n",
            "\n",
            "```python\n",
            "def add_numbers(a, b):\n",
            "    return a + b\n",
            "\n",
            "print(add_numbers(5, 10))\n",
            "```\n",
            "\n",
            "**Fixes made:**\n",
            "1. Added a colon `:` at the end of the function definition line.\n",
            "2. Indented the `return` statement inside the function.\n",
            "3. Added a closing parenthesis `)` on the `print` statement.\n"
          ]
        }
      ],
      "source": [
        "def fix_code():\n",
        "    user_prompt = \"\"\"\n",
        "    fix this buggy python code:\n",
        "    def add_numbers(a, b)\n",
        "    return a + b\n",
        "    print(add_numbers(5, 10)\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    generated_code = response.choices[0].message.content\n",
        "    print(\"\\n=== Generated Code ===\\n\")\n",
        "    print(generated_code)\n",
        "\n",
        "    return generated_code\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    code = fix_code()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4ee91ea9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ee91ea9",
        "outputId": "88fe6c15-7e47-4c48-9dae-f6cf6d09736a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n"
          ]
        }
      ],
      "source": [
        "def add_numbers(a, b):\n",
        "    return a + b\n",
        "\n",
        "print(add_numbers(5, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c4f9247",
      "metadata": {
        "id": "6c4f9247"
      },
      "source": [
        "#### 18. Summarize this text to 2-3 sentences by using API call.\n",
        "\n",
        "\"Generative AI, sometimes called \"gen AI\", refers to deep learning models that can create complex original content such as long-form text, high-quality images, realistic video or audio and more in response to a user’s prompt or request.\n",
        "\n",
        "At a high level, generative models encode a simplified representation of their training data, and then draw from that representation to create new work that’s similar, but not identical, to the original data.\n",
        "\n",
        "Generative models have been used for years in statistics to analyze numerical data. But over the last decade, they evolved to analyze and generate more complex data types. This evolution coincided with the emergence of three sophisticated deep learning model types:\n",
        "\n",
        "Variational autoencoders or VAEs, which were introduced in 2013, and enabled models that could generate multiple variations of content in response to a prompt or instruction.\n",
        "\n",
        "Diffusion models, first seen in 2014, which add \"noise\" to images until they are unrecognizable, and then remove the noise to generate original images in response to prompts.\n",
        "\n",
        "Transformers (also called transformer models), which are trained on sequenced data to generate extended sequences of content (such as words in sentences, shapes in an image, frames of a video or commands in software code). Transformers are at the core of most of today’s headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard and Midjourney.\"\n",
        "\n",
        "[<p align=\"right\"> <cite> Source: What is generative AI? </cite></p>](https://www.ibm.com/think/topics/generative-ai)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "275efb3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "275efb3b",
        "outputId": "7a84e951-d436-4256-b698-e71639a02837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Summary (2–3 sentences) ===\n",
            "\n",
            "Generative AI refers to deep learning models that create original content like text, images, and audio by drawing from simplified representations of their training data. Over the past decade, generative models have evolved with key advances in variational autoencoders, diffusion models, and transformer models—the latter powering many popular AI tools such as ChatGPT and GPT-4. These technologies enable the generation of complex, nuanced outputs in response to user prompts.\n"
          ]
        }
      ],
      "source": [
        "def summarize_text():\n",
        "    user_prompt = \"\"\"\n",
        "    Summarize the following text into 2–3 sentences:\n",
        "\n",
        "    Generative AI, sometimes called \"gen AI\", refers to deep learning models that can create complex original content such as long-form text, high-quality images, realistic video or audio and more in response to a user's prompt or request.\n",
        "\n",
        "    At a high level, generative models encode a simplified representation of their training data, and then draw from that representation to create new work that's similar, but not identical, to the original data.\n",
        "\n",
        "    Generative models have been used for years in statistics to analyze numerical data. But over the last decade, they evolved to analyze and generate more complex data types. This evolution coincided with the emergence of three sophisticated deep learning model types:\n",
        "\n",
        "    Variational autoencoders or VAEs, which were introduced in 2013, and enabled models that could generate multiple variations of content in response to a prompt or instruction.\n",
        "\n",
        "    Diffusion models, first seen in 2014, which add \"noise\" to images until they are unrecognizable, and then remove the noise to generate original images in response to prompts.\n",
        "\n",
        "    Transformers (also called transformer models), which are trained on sequenced data to generate extended sequences of content (such as words in sentences, shapes in an image, frames of a video or commands in software code). Transformers are at the core of most of today's headline-making generative AI tools, including ChatGPT and GPT-4, Copilot, BERT, Bard and Midjourney.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Summary (2–3 sentences) ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    summarize_text()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2b1ed6",
      "metadata": {
        "id": "5d2b1ed6"
      },
      "source": [
        "#### 19. Translate the following idioms into another language, ensuring the meaning is preserved (not just word-for-word translation):\n",
        "\n",
        "1. \"It's raining cats and dogs.\"\n",
        "2. \"Break a leg.\"\n",
        "3. \"Kill two birds with one stone.\"\n",
        "4. \"Spill the beans.\"\n",
        "5. \"A blessing in disguise.\"\n",
        "\n",
        "Try to improve the response as much as possible and evaluate the accuracy of the final output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ee29a46e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee29a46e",
        "outputId": "c0de3718-e8d0-4461-ee3b-6ec6418880a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Idiom Translations ===\n",
            "\n",
            "Certainly! Here are the Tamil translations of the given English idioms, preserving their meanings rather than translating them literally, followed by a brief evaluation of each translation’s accuracy.\n",
            "\n",
            "---\n",
            "\n",
            "### 1. \"It's raining cats and dogs.\"\n",
            "**Tamil Translation:**  \n",
            "**மழை செட்டையாய் விழுகிறது.**  \n",
            "Literal meaning: \"It is raining heavily.\"\n",
            "\n",
            "**Evaluation:**  \n",
            "In Tamil, there is no direct equivalent involving animals, so this phrase is commonly rendered simply as “மழை செட்டையாய் விழுகிறது” or “மிகுதி மழை வருகிற,” which means heavy or torrential rain. This captures the meaning accurately without a word-for-word translation.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. \"Break a leg.\"\n",
            "**Tamil Translation:**  \n",
            "**வெற்றி பெற வாழ்த்து!** (Transliteration: *Vettri pera vaazhthu!*)  \n",
            "Meaning: “Wishing you success!”\n",
            "\n",
            "Or more idiomatically used in performance contexts:  \n",
            "**நல்ல நடிப்புச் சூப்பர்!** (Meaning: “Good performance!”) — Though not an idiom, conveys goodwill before a performance.\n",
            "\n",
            "**Evaluation:**  \n",
            "“Break a leg” is a theatrical expression wishing good luck. Tamil doesn’t have a direct equivalent idiom that implies ‘luck by wishing misfortune.’ Instead, expressing “வெற்றி பெற வாழ்த்து” (best wishes to succeed) maintains the intended sentiment and is commonly used. The translation is conceptually accurate even if the phrase isn’t idiomatic.\n",
            "\n",
            "---\n",
            "\n",
            "### 3. \"Kill two birds with one stone.\"\n",
            "**Tamil Translation:**  \n",
            "**ஒரே ஒரு முயற்சியில் இரண்டு பிரச்சனைகளுக்கு தீர்வு காண்கிறேன்.**  \n",
            "Or more idiomatic:  \n",
            "**ஒரே ஓர் ஆட்டில் இரண்டு முட்டைகள் அடித்தல்.**  \n",
            "(Transliterated: *Oree or aattil irandu muttaigal adiththal.*)  \n",
            "Meaning: “Hitting two eggs in one shot.”\n",
            "\n",
            "**Evaluation:**  \n",
            "The Tamil idiom “ஒரே ஓர் ஆட்டில் இரண்டு முட்டைகள் அடித்தல்” conveys achieving two outcomes in a single effort, similar to the English idiom. This is a good cultural adaptation, as Tamil doesn’t commonly use birds and stones in this context. This translation is accurate and keeps the meaning intact.\n",
            "\n",
            "---\n",
            "\n",
            "### 4. \"Spill the beans.\"\n",
            "**Tamil Translation:**  \n",
            "**ரகசியம் வெளிச் செல்லுதல்.** (Meaning: \"The secret comes out.\")  \n",
            "Or idiomatically:  \n",
            "**கொசு கையில் இருந்து ஓடுவது.** (Transliteration: *Kosu kaiyil irundhu ooduvathu.* Meaning: “The mosquito escapes from the hand.”)\n",
            "\n",
            "**Evaluation:**  \n",
            "There is no exact Tamil idiom matching “spill the beans.” “ரகசியம் வெளிச்ச செல்லுதல்” is a direct but meaningful way to say “to reveal a secret.” The mosquito phrase metaphorically suggests inability to keep hold of a secret, which somewhat matches the meaning. Though less idiomatic, the translation is conceptually accurate.\n",
            "\n",
            "---\n",
            "\n",
            "### 5. \"A blessing in disguise.\"\n",
            "**Tamil Translation:**  \n",
            "**முரட்டான முகமோடும் நல்ல காரியமோடும்.**  \n",
            "Or more simply:  \n",
            "**திடுக்கிடும் காட்சி ஆனால் பயனுள்ள விடை.**  \n",
            "Meaning: “A surprising appearance but beneficial outcome.”\n",
            "\n",
            "**Evaluation:**  \n",
            "Tamil speakers often use a phrase like “கஷ்டம் தோன்றினாலும் நன்மை இருக்கிறது” (“Though hardship appears, there is benefit”), which captures the sense of something initially seeming bad but ultimately good. This is accurate in preserving meaning though not a fixed idiom. The translation is conceptually precise and understandable.\n",
            "\n",
            "---\n",
            "\n",
            "### Summary Table\n",
            "\n",
            "| English Idiom                     | Tamil Equivalent/Meaning                        | Accuracy Evaluation                 |\n",
            "|---------------------------------|------------------------------------------------|-----------------------------------|\n",
            "| It’s raining cats and dogs.     | மழை செட்டையாய் விழுகிறது                         | Accurately conveys heavy rain     |\n",
            "| Break a leg.                    | வெற்றி பெற வாழ்த்து!                              | Accurate wish for success          |\n",
            "| Kill two birds with one stone.  | ஒரே ஓர் ஆட்டில் இரண்டு முட்டைகள் அடித்தல்         | Good cultural equivalent           |\n",
            "| Spill the beans.                | ரகசியம் வெளிச்ச செல்லுதல்                         | Meaning preserved; less idiomatic |\n",
            "| A blessing in disguise.         | கஷ்டம் தோன்றினாலும் நன்மை இருக்கிறது              | Conceptually accurate              |\n",
            "\n",
            "---\n",
            "\n",
            "If you'd like, I can provide literal translations too, or idioms from other Indian languages.\n"
          ]
        }
      ],
      "source": [
        "def translate_idioms():\n",
        "    user_prompt = \"\"\"\n",
        "    Translate the following English idioms into another language (Tamil),\n",
        "    ensuring the meaning is preserved and not translated word-for-word.\n",
        "    Then briefly evaluate the accuracy of each translation.\n",
        "\n",
        "    1. \"It's raining cats and dogs.\"\n",
        "    2. \"Break a leg.\"\n",
        "    3. \"Kill two birds with one stone.\"\n",
        "    4. \"Spill the beans.\"\n",
        "    5. \"A blessing in disguise.\"\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Idiom Translations ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    translate_idioms()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dab34e8f",
      "metadata": {
        "id": "dab34e8f"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1c8b2d87",
      "metadata": {
        "id": "1c8b2d87"
      },
      "source": [
        "#### 20. Count how many times the letter \"R\" appears in the word \"Strawberry\".\n",
        "\n",
        "Write a prompt that ensures an AI can correctly count how many times the letter \"R\" appears in the word \"Strawberry.\" Write a clear and precise prompt that guarantees the correct answer (3).\n",
        "\n",
        "Explain why your prompt is effective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "a76c65b6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a76c65b6",
        "outputId": "9f5af446-6cef-4905-ef35-d7e9d22920a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Idiom Translations ===\n",
            "\n",
            "Let's analyze the word \"Straberry\":\n",
            "\n",
            "1. Separate the letters by \"-\" gives:  \n",
            "   S - t - r - a - b - e - r - r - y\n",
            "\n",
            "2. Count how many \"r\" appear:\n",
            "   Letters are: S, t, **r**, a, b, e, **r**, **r**, y  \n",
            "   The letter \"r\" appears **3 times**.\n",
            "\n",
            "**Answer:** There are 3 \"r\"s in \"Straberry\".\n"
          ]
        }
      ],
      "source": [
        "def count_r():\n",
        "    user_prompt = \"\"\"\n",
        "    How many r appears in Straberry after separating letters by -\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Idiom Translations ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    count_r()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea3d44c",
      "metadata": {
        "id": "2ea3d44c"
      },
      "source": [
        "It clearly defines the task asking for a count of a specific letter (“r”), which gives the model a concrete, measurable objective.\n",
        "\n",
        "The “separating letters by -” part forces the model to think step by step\n",
        ", this phrasing nudges the model to: break the word into individual characters, inspect each one and count occurrences\n",
        "\n",
        "Its a simple enough to avoid confusion where short prompts often work better for small, well defined tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "057aa6db",
      "metadata": {
        "id": "057aa6db"
      },
      "source": [
        "#### 21. Generate a paragraph about a cat without using the letter 'e'.\n",
        "\n",
        "Write a prompt that forces the AI to produce a three-sentence story about a cat while strictly forbidding it to use letter 'e'.\n",
        "\n",
        "Explain why your prompt is effective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "f6fc6375",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6fc6375",
        "outputId": "afab1229-f40d-4cea-83ef-f0f43b9f5da4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Idiom Translations ===\n",
            "\n",
            "A small cat sat by a tall oak, watching birds dart. Mist swirled softly around its paws, cool and calm. Nightfall brought stars, and with a purr, cat drifted into a soft drift.\n"
          ]
        }
      ],
      "source": [
        "def cat_wo_e():\n",
        "    user_prompt = \"\"\"\n",
        "    Write a three-sentence story about a cat, and strictly avoid using the letter \"e\" anywhere in the output. Do not include words, names, or grammatical forms that contain this letter. Produce only the story and nothing else.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Idiom Translations ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cat_wo_e()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05bcfd77",
      "metadata": {
        "id": "05bcfd77"
      },
      "source": [
        "It gives a clear structural requirement, explicitly tell the model to produce three sentences, which removes ambiguity about length and format.\n",
        "\n",
        "It states the forbidden letter explicitly and repeatedly\n",
        "By saying: “strictly avoid using the letter 'e'” and “Do not include words… that contain this letter”\n",
        "-reinforce the constraint in two different ways. This reduces the chance of accidental violations, especially since “e” is the most common letter in English.\n",
        "\n",
        "It is simple, direct, and unambiguous where the model performs best when the task is: very specific, measurable and rule based"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "885b4cea",
      "metadata": {
        "id": "885b4cea"
      },
      "source": [
        "#### 22. Extract JSON Data from the input text in two different ways.\n",
        "\n",
        "Input Text: \"Our trip to Tokyo starts on June 12th. We're staying for 5 nights at the Park Hyatt before heading to Kyoto.\"\n",
        "\n",
        "Extract the information from the text above using two different methods:\n",
        "\n",
        "1. Write a prompt asking the AI to return a JSON object with the fields `destination`, `start_date`, and `stay_duration`.\n",
        "\n",
        "2. Instead of putting rules in the prompt, provide a specific JSON schema that defines the field names and their required data types `destination` (the first city), `start_date` (formatted as YYYY-MM-DD), and `stay_duration` (the number of nights as an integer).\n",
        "\n",
        "Which method yields a more reliable result for a computer program to process, and why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "704b0f1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "704b0f1f",
        "outputId": "cfb844c6-fc4f-463c-9e7e-d0f127f0e30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Idiom Translations ===\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"destination\": \"Tokyo\",\n",
            "  \"start_date\": \"June 12th\",\n",
            "  \"stay_duration\": \"5 nights\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "def json_create():\n",
        "    user_prompt = \"\"\"\n",
        "   Extract the following information from the text and return it strictly as a JSON object with the fields: destination, start_date, and stay_duration. Do not include any explanation or extra text.\n",
        "\n",
        "Input:\n",
        "\"Our trip to Tokyo starts on June 12th. We're staying for 5 nights at the Park Hyatt before heading to Kyoto.\"\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Idiom Translations ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    json_create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "6bfdb824",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfdb824",
        "outputId": "d9027c58-e166-4d60-9746-f7377f4691c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Idiom Translations ===\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"destination\": \"Tokyo\",\n",
            "  \"start_date\": \"2024-06-12\",\n",
            "  \"stay_duration\": 5\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "def json_create_2():\n",
        "    user_prompt = \"\"\"\n",
        "Extract structured information from the following text and return it strictly in the JSON format defined by the schema below.\n",
        "\n",
        "Text:\n",
        "\"Our trip to Tokyo starts on June 12th. We're staying for 5 nights at the Park Hyatt before heading to Kyoto.\"\n",
        "\n",
        "JSON Schema:\n",
        "{\n",
        "  \"type\": \"object\",\n",
        "  \"properties\": {\n",
        "    \"destination\": { \"type\": \"string\" },\n",
        "    \"start_date\": { \"type\": \"string\", \"format\": \"date\" },\n",
        "    \"stay_duration\": { \"type\": \"integer\" }\n",
        "  },\n",
        "  \"required\": [\"destination\", \"start_date\", \"stay_duration\"]\n",
        "}\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Idiom Translations ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    json_create_2()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e9ecb9c",
      "metadata": {
        "id": "4e9ecb9c"
      },
      "source": [
        "Between the two extraction approaches used, the JSON schema method is far more reliable for a computer program to proces:\n",
        "\n",
        "It enforces strict structure\n",
        "A schema defines: exact field names, required fields, data types, formatting rules.\n",
        "\n",
        "It produces machine readable, predictable output: valid, structured, predictable\n",
        "easy to parse.\n",
        "\n",
        "This reduces interpretation errors, formatting mistakes, variability in output."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e385a68",
      "metadata": {
        "id": "4e385a68"
      },
      "source": [
        "#### 23. Create a structured table comparing different programming languages.\n",
        "\n",
        "Write a prompt that generates a table in this format (example below) with accurate information.\n",
        "\n",
        "| Language    | Use Case               | Advantages                     | Disadvantages                |\n",
        "|-------------|------------------------|---------------------------------|------------------------------|\n",
        "| Python      | Data Science, AI       | Easy to learn, versatile       | Slower execution speed       |\n",
        "| Java        | Enterprise Applications| Platform-independent, robust   | Verbose syntax               |\n",
        "| JavaScript  | Web Development        | Fast, widely supported         | Limited for backend tasks    |\n",
        "\n",
        "**Tip**: To enhance readability, you can copy and paste the generated table into a Markdown cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "7fdc8d2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fdc8d2a",
        "outputId": "9c6641db-2306-44c2-a716-14afb7c04c22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Idiom Translations ===\n",
            "\n",
            "| Language   | Use Case               | Advantages                          | Disadvantages               |\n",
            "|------------|------------------------|-------------------------------------|-----------------------------|\n",
            "| Python     | Web development, Data Science, Automation | Easy to learn, Extensive libraries | Slower execution speed       |\n",
            "| JavaScript | Web development, Frontend & Backend     | Runs in all browsers, Large community | Can be inconsistent across browsers |\n",
            "| C++        | System/software development, Game dev    | High performance, Control over system resources | Complex syntax, Steeper learning curve |\n"
          ]
        }
      ],
      "source": [
        "def languages_table():\n",
        "    user_prompt = \"\"\"\n",
        "Create a Markdown table comparing programming languages using the exact format below:\n",
        "\n",
        "| Language   | Use Case               | Advantages                          | Disadvantages               |\n",
        "|------------|------------------------|-------------------------------------|-----------------------------|\n",
        "\n",
        "Fill the table with accurate information for at least three programming languages.\n",
        "Use the same column names, alignment, and formatting.\n",
        "Ensure each row includes:\n",
        "- The language name\n",
        "- Its primary use case(s)\n",
        "- Two or more advantages\n",
        "- One or more disadvantages\n",
        "\n",
        "Do not add explanations or text outside the table. Output only the final Markdown table.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Idiom Translations ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    languages_table()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "=== Idiom Translations ===\n",
        "\n",
        "| Language   | Use Case               | Advantages                          | Disadvantages               |\n",
        "|------------|------------------------|-------------------------------------|-----------------------------|\n",
        "| Python     | Web development, Data Science, Automation | Easy to learn, Extensive libraries | Slower execution speed       |\n",
        "| JavaScript | Web development, Frontend & Backend     | Runs in all browsers, Large community | Can be inconsistent across browsers |\n",
        "| C++        | System/software development, Game dev    | High performance, Control over system resources | Complex syntax, Steeper learning curve |"
      ],
      "metadata": {
        "id": "4Zp1Fr1yYX7B"
      },
      "id": "4Zp1Fr1yYX7B"
    },
    {
      "cell_type": "markdown",
      "id": "7bc480dd",
      "metadata": {
        "id": "7bc480dd"
      },
      "source": [
        "#### 24. Generate a quiz about machine learning basics.\n",
        "\n",
        "Look at the example below and write a prompt that generates a quiz with identical formatting. Ensure the title formatting, list markers (a, b, c, d), and the correct answer indicator (*) are accurately replicated.\n",
        "\n",
        "**Machine learning basics quiz**\n",
        "\n",
        "1. Which of the following best describes supervised learning?  \n",
        "a) The model learns from unlabeled data to find hidden patterns  \n",
        "b) The model learns from labeled data to make predictions *  \n",
        "c) The model is programmed with explicit rules  \n",
        "d) The model randomly guesses outputs without training\n",
        "\n",
        "2. Which of these is a common application of machine learning in everyday life?  \n",
        "a) Sorting files manually on a computer  \n",
        "b) Email spam filtering *  \n",
        "c) Writing code by hand  \n",
        "d) Using a calculator for arithmetic\n",
        "\n",
        "3. What is overfitting in machine learning?  \n",
        "a) When the model performs well on new, unseen data  \n",
        "b) When the model is too simple and underperforms  \n",
        "c) When the model learns the training data too well, including noise, reducing generalization *  \n",
        "d) When the model runs faster than expected\n",
        "\n",
        "4. Which ethical concern is commonly associated with machine learning algorithms?  \n",
        "a) Increased hardware costs  \n",
        "b) Bias in training data leading to unfair predictions *  \n",
        "c) The inability to process large datasets  \n",
        "d) Lack of available programming languages\n",
        "\n",
        "5. Which of the following is NOT a type of machine learning?  \n",
        "a) Supervised learning  \n",
        "b) Reinforcement learning  \n",
        "c) Unsupervised learning  \n",
        "d) Manual learning *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "49534fde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49534fde",
        "outputId": "93eaeaa3-9967-4ae8-a1c4-7886ca7ca0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Idiom Translations ===\n",
            "\n",
            "Machine learning basics quiz\n",
            "\n",
            "1. What is the primary goal of supervised learning?  \n",
            "   a) To find patterns in unlabeled data  \n",
            "   b) To learn from labeled data to make predictions *  \n",
            "   c) To reduce dimensionality of data  \n",
            "   d) To cluster similar data points  \n",
            "\n",
            "2. Which algorithm is commonly used for classification tasks?  \n",
            "   a) Linear regression  \n",
            "   b) K-means clustering  \n",
            "   c) Decision trees *  \n",
            "   d) Principal component analysis  \n",
            "\n",
            "3. What does overfitting mean in machine learning?  \n",
            "   a) The model performs well on new data  \n",
            "   b) The model is too simple  \n",
            "   c) The model memorizes training data but fails on unseen data *  \n",
            "   d) The model ignores training data  \n",
            "\n",
            "4. Which of the following is an example of unsupervised learning?  \n",
            "   a) Predicting house prices  \n",
            "   b) Image classification  \n",
            "   c) Customer segmentation *  \n",
            "   d) Spam email detection  \n",
            "\n",
            "5. What is a common measure of error for regression problems?  \n",
            "   a) Accuracy  \n",
            "   b) Mean squared error *  \n",
            "   c) Confusion matrix  \n",
            "   d) Recall\n"
          ]
        }
      ],
      "source": [
        "def ML_Quiz():\n",
        "    user_prompt = \"\"\"\n",
        "Generate a quiz titled \"Machine learning basics quiz\".\n",
        "\n",
        "Follow this exact formatting:\n",
        "\n",
        "Machine learning basics quiz\n",
        "\n",
        "1. [Question text]\n",
        "   a) [Option A]\n",
        "   b) [Option B]\n",
        "   c) [Option C]\n",
        "   d) [Option D]\n",
        "\n",
        "Mark the correct answer by placing an asterisk (*) at the end of the correct option, exactly like this example:\n",
        "\n",
        "b) The model learns from labeled data to make predictions *\n",
        "\n",
        "Create 5 multiple‑choice questions about machine learning basics using this identical structure, spacing, indentation, and answer‑marking style. Do not add explanations or extra text.\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Idiom Translations ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ML_Quiz()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce21991c",
      "metadata": {
        "id": "ce21991c"
      },
      "source": [
        "#### 25. Create a comprehensive online course outline for beginners.\n",
        "\n",
        "Write a prompt that generates entire course outline, following the example provided below. Ensure the prompt is detailed enough to cover all sections, with clear formatting and practical guidance.\n",
        "\n",
        "Sections to include in course outline:\n",
        "- Course overview - description, objectives, target audience.\n",
        "- Module breakdown - 5 modules with title, short description, three key learning outcomes and an interactive assignment in the end.\n",
        "- Assessment plan - a table outlining the assessment methods with description and weightgage.\n",
        "- Certification criteria - requirements to earn a certificate.\n",
        "- Marketing strategy - step-by-step guide for promoting the course.\n",
        "\n",
        "Include a detailed description of the type of information each section should contain. Maintain the same formatting, section titles, and course name. While the generated descriptions, modules and marketing strategy steps may differ and incorporate new ideas and concepts, it must remain aligned with the theme of the task.\n",
        "\n",
        "Put the final output of your API call in a new Markdown cell.\n",
        "\n",
        "#### Example:\n",
        "---\n",
        "---\n",
        "## Course Outline: Mastering Prompt Engineering for AI Applications\n",
        "\n",
        "---\n",
        "\n",
        "### Course Overview\n",
        "This beginner-friendly course is designed to equip learners with the foundational skills and knowledge required to craft effective prompts for AI applications. By mastering prompt engineering, students will learn how to optimize AI models for various tasks, including text generation, data analysis, and creative problem-solving. The course is ideal for individuals interested in AI, developers, data scientists, and anyone looking to leverage AI tools in their personal or professional projects.\n",
        "\n",
        "#### Objectives\n",
        "- Understand the principles of prompt engineering and its role in AI workflows.\n",
        "- Learn techniques to design, test, and refine prompts for optimal AI performance.\n",
        "- Apply prompt engineering skills to real-world scenarios and projects.\n",
        "\n",
        "#### Target Audience\n",
        "- Beginners with no prior experience in AI or programming.\n",
        "- Professionals seeking to integrate AI into their workflows.\n",
        "- Students and enthusiasts curious about AI capabilities.\n",
        "\n",
        "---\n",
        "\n",
        "### Module Breakdown\n",
        "\n",
        "#### Module 1: Introduction to Prompt Engineering\n",
        "- **Description:** This module introduces the concept of prompt engineering, its importance in AI applications, and the basics of interacting with AI models.\n",
        "- **Key Learning Outcomes:**\n",
        "  1. Define prompt engineering and its significance in AI workflows.\n",
        "  2. Understand the structure and components of effective prompts.\n",
        "  3. Explore real-world use cases of prompt engineering.\n",
        "- **Interactive Assignment:** Write a simple prompt for a text-generation AI model to generate a short story.\n",
        "\n",
        "---\n",
        "\n",
        "#### Module 2: Principles of Effective Prompt Design\n",
        "- **Description:** Learn the core principles and techniques for designing prompts that yield accurate and relevant AI outputs.\n",
        "- **Key Learning Outcomes:**\n",
        "  1. Identify factors that influence AI responses (e.g., context, specificity, tone).\n",
        "  2. Explore strategies for iterative prompt refinement.\n",
        "  3. Understand common pitfalls and how to avoid them.\n",
        "- **Interactive Assignment:** Design and test three variations of a prompt for a chatbot to answer customer queries effectively.\n",
        "\n",
        "---\n",
        "\n",
        "#### Module 3: Advanced Techniques in Prompt Engineering\n",
        "- **Description:** Dive deeper into advanced methods, including chaining prompts, dynamic prompts, and leveraging AI tools for complex tasks.\n",
        "- **Key Learning Outcomes:**\n",
        "  1. Learn how to chain prompts for multi-step tasks.\n",
        "  2. Explore dynamic prompt techniques for adaptive AI responses.\n",
        "  3. Understand how to integrate external data sources into prompts.\n",
        "- **Interactive Assignment:** Create a multi-step prompt to generate a detailed report based on user-provided data.\n",
        "\n",
        "---\n",
        "\n",
        "#### Module 4: Applications of Prompt Engineering Across Industries\n",
        "- **Description:** Discover how prompt engineering is applied in various industries, such as healthcare, education, marketing, and software development.\n",
        "- **Key Learning Outcomes:**\n",
        "  1. Analyze industry-specific use cases of prompt engineering.\n",
        "  2. Learn how to tailor prompts for different domains and objectives.\n",
        "  3. Explore ethical considerations in prompt engineering.\n",
        "- **Interactive Assignment:** Develop a prompt for a marketing campaign, including product descriptions and social media posts.\n",
        "\n",
        "---\n",
        "\n",
        "#### Module 5: Building and Testing AI Projects with Prompt Engineering\n",
        "- **Description:** Apply your skills to design, test, and deploy AI projects using prompt engineering techniques.\n",
        "- **Key Learning Outcomes:**\n",
        "  1. Plan and execute an AI project using prompt engineering.\n",
        "  2. Test and refine prompts for optimal project outcomes.\n",
        "  3. Document and present your project effectively.\n",
        "- **Interactive Assignment:** Create a mini-project using prompt engineering to solve a real-world problem (e.g., automating customer support).\n",
        "\n",
        "---\n",
        "\n",
        "### Assessment Plan\n",
        "\n",
        "| Assessment Method      | Description                          | Weightage (%) |\n",
        "|------------------------|--------------------------------------|---------------|\n",
        "| Quizzes               | Multiple-choice quizzes after each module | 30%          |\n",
        "| Assignments           | Practical exercises for each module  | 40%           |\n",
        "| Final Project         | A comprehensive project combining all skills | 20%          |\n",
        "| Participation         | Active participation in discussions  | 10%           |\n",
        "\n",
        "---\n",
        "\n",
        "### Certification Criteria\n",
        "To earn a certificate of completion, students must:\n",
        "1. Achieve a minimum score of 70% across all assessments.\n",
        "2. Submit all interactive assignments and the final project.\n",
        "3. Actively participate in at least 80% of discussion forums and live sessions.\n",
        "\n",
        "---\n",
        "\n",
        "### Marketing Strategy\n",
        "\n",
        "#### Step 1: Social Media Campaigns\n",
        "- Create engaging posts highlighting the course benefits, modules, and outcomes.\n",
        "- Share testimonials and success stories from beta testers or early participants.\n",
        "- Use targeted ads on platforms like LinkedIn, Facebook, and Instagram.\n",
        "\n",
        "#### Step 2: Email Marketing\n",
        "- Build an email list of potential learners (e.g., professionals, students).\n",
        "- Send a series of emails introducing the course, its benefits, and enrollment deadlines.\n",
        "- Include exclusive early-bird discounts and referral incentives.\n",
        "\n",
        "#### Step 3: Partnerships\n",
        "- Collaborate with universities, coding bootcamps, and AI communities to promote the course.\n",
        "- Partner with influencers and thought leaders in the AI space for endorsements.\n",
        "\n",
        "#### Step 4: Content Creation\n",
        "- Publish blog posts, videos, and webinars on topics related to prompt engineering.\n",
        "- Share free resources (e.g., mini-guides, templates) to attract interest.\n",
        "- Host live Q&A sessions to engage with the audience and answer questions about the course.\n",
        "\n",
        "#### Step 5: Testimonials and Reviews\n",
        "- Collect feedback from early participants and showcase their success stories.\n",
        "- Encourage learners to share their experiences on social media and review platforms.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "ba33992f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba33992f",
        "outputId": "60bf26e2-bf91-40df-ecf9-e8d7f139cadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Idiom Translations ===\n",
            "\n",
            "Course Outline: Mastering Prompt Engineering for AI Applications\n",
            "\n",
            "---\n",
            "\n",
            "**Course Overview**  \n",
            "This course provides a comprehensive introduction to prompt engineering—the process of designing and refining inputs to optimize AI model outputs. Learners will explore foundational concepts, practical techniques, and ethical considerations for crafting effective prompts across various AI applications. The curriculum emphasizes hands-on learning to empower beginners in harnessing the full potential of AI-driven tools in natural language processing.\n",
            "\n",
            "**Course Objectives**  \n",
            "- Understand core principles and terminology of prompt engineering.  \n",
            "- Develop skills to create clear, concise, and goal-oriented prompts.  \n",
            "- Analyze and improve prompt effectiveness through iterative testing.  \n",
            "- Apply prompt engineering strategies to real-world AI applications.  \n",
            "- Recognize ethical issues related to prompt design and AI output fairness.\n",
            "\n",
            "**Target Audience**  \n",
            "This course is designed for beginners with little to no background in AI or programming who are interested in leveraging AI tools effectively. No prior experience in machine learning or coding is required, though basic computer literacy and familiarity with web applications are helpful.\n",
            "\n",
            "---\n",
            "\n",
            "**Module Breakdown**\n",
            "\n",
            "**Module 1: Introduction to Prompt Engineering**  \n",
            "- Description: This module introduces the fundamental concepts of prompt engineering, explaining what prompts are and why they are crucial in interacting with AI models. Learners will get an overview of AI language models and their response mechanisms.  \n",
            "- Key Learning Outcomes:  \n",
            "  1. Define prompt engineering and its role in AI interactions.  \n",
            "  2. Understand how AI language models process prompts.  \n",
            "  3. Identify common use cases where prompt engineering is applied.  \n",
            "- Interactive Assignment: Write three different prompts for a simple AI text generation task and compare the responses to observe variations.\n",
            "\n",
            "---\n",
            "\n",
            "**Module 2: Crafting Effective Prompts**  \n",
            "- Description: Learners will explore best practices for writing clear, concise, and context-rich prompts to guide AI models toward desired outputs. The module covers prompt structure and language nuances.  \n",
            "- Key Learning Outcomes:  \n",
            "  1. Recognize components of clear and effective prompts.  \n",
            "  2. Experiment with prompt length, specificity, and tone.  \n",
            "  3. Evaluate prompt clarity through peer review and iteration.  \n",
            "- Interactive Assignment: Revise given sample prompts based on clarity and specificity guidelines, then test and analyze output improvements.\n",
            "\n",
            "---\n",
            "\n",
            "**Module 3: Techniques for Prompt Optimization**  \n",
            "- Description: This module focuses on iterative methods and experimental approaches such as zero-shot, few-shot, and chain-of-thought prompting to enhance AI responses. Learners will practice optimizing prompts to solve complex tasks.  \n",
            "- Key Learning Outcomes:  \n",
            "  1. Differentiate between zero-shot, few-shot, and chain-of-thought prompting.  \n",
            "  2. Apply iterative testing to refine prompt effectiveness.  \n",
            "  3. Measure and document prompt performance improvements.  \n",
            "- Interactive Assignment: Conduct an iterative prompt refinement cycle for a defined problem and submit a report on changes and results.\n",
            "\n",
            "---\n",
            "\n",
            "**Module 4: Prompt Engineering Across AI Applications**  \n",
            "- Description: Learners will explore how prompt engineering techniques are adapted to various AI applications, including chatbots, creative writing, data extraction, and summarization.  \n",
            "- Key Learning Outcomes:  \n",
            "  1. Identify domain-specific prompt strategies.  \n",
            "  2. Customize prompts for different AI-driven tasks.  \n",
            "  3. Integrate prompts into simple application workflows.  \n",
            "- Interactive Assignment: Design a prompt tailored for a chatbot to handle a customer service request and demonstrate its effectiveness.\n",
            "\n",
            "---\n",
            "\n",
            "**Module 5: Ethics and Future Trends in Prompt Engineering**  \n",
            "- Description: This module examines ethical concerns such as bias, misinformation, and user manipulation in AI outputs and discusses emerging trends and tools influencing prompt engineering.  \n",
            "- Key Learning Outcomes:  \n",
            "  1. Recognize ethical challenges in prompt design and AI output.  \n",
            "  2. Explore guidelines for responsible prompt crafting.  \n",
            "  3. Discover evolving tools and future directions in prompt engineering.  \n",
            "- Interactive Assignment: Participate in a discussion forum to analyze a case study involving biased AI outputs and propose ethical prompt adjustments.\n",
            "\n",
            "---\n",
            "\n",
            "**Assessment Plan**\n",
            "\n",
            "| Assessment Method           | Description                                         | Weightage (%) |\n",
            "|----------------------------|-----------------------------------------------------|---------------|\n",
            "| Module Quizzes             | Short quizzes after each module to reinforce learning concepts and terminology. | 30            |\n",
            "| Interactive Assignments    | Hands-on tasks that involve prompt writing, testing, and refinement with submitted reports or reflections. | 40            |\n",
            "| Final Project              | Design and present a comprehensive prompt solution for a specific AI application, including rationale and evaluation. | 30            |\n",
            "\n",
            "---\n",
            "\n",
            "**Certification Criteria**  \n",
            "1. Achieve a minimum passing score of 70% across all quizzes and assignments.  \n",
            "2. Complete and submit all interactive assignments and the final project.  \n",
            "3. Actively participate in at least three module discussion forums or peer reviews.  \n",
            "\n",
            "---\n",
            "\n",
            "**Marketing Strategy**  \n",
            "1. **Social Media Campaigns**  \n",
            "   Leverage platforms like LinkedIn, Twitter, and Instagram to post introductory videos, infographics, and learner testimonials to raise awareness.  \n",
            "2. **Email Newsletters**  \n",
            "   Send targeted emails to mailing lists at educational institutions, AI communities, and professional networks highlighting the course benefits and enrollment dates.  \n",
            "3. **Webinars and Live Demos**  \n",
            "   Host free live sessions showcasing prompt engineering basics and answering questions to generate interest and trust.  \n",
            "4. **Affiliate Partnerships**  \n",
            "   Collaborate with AI influencers, bloggers, and related course platforms to promote the course through reviews and referral discounts.  \n",
            "5. **Content Marketing**  \n",
            "   Publish blog posts, case studies, and how-to guides on prompt engineering tailored for beginners, driving organic traffic to the course landing page.  \n",
            "6. **Online Communities Engagement**  \n",
            "   Participate in AI, machine learning, and technology forums (Reddit, Discord, etc.) by sharing valuable insights and subtly promoting the course.  \n",
            "7. **Early Bird Discounts and Bundles**  \n",
            "   Offer limited-time discounts or bundle the course with complementary training programs to incentivize early registration.  \n",
            "8. **Certification Showcases**  \n",
            "   Highlight the certification's value for career advancement and include sample badges learners can display on LinkedIn profiles to attract aspirants focused on credentials.\n"
          ]
        }
      ],
      "source": [
        "def Course_Outline():\n",
        "    user_prompt = \"\"\"\n",
        "Create a full course outline titled:\n",
        "Course Outline: Mastering Prompt Engineering for AI Applications\n",
        "\n",
        "Follow the exact formatting style shown in the example, including section titles, spacing, and structure.\n",
        "Generate original content, but keep it aligned with a beginner‑friendly course on prompt engineering.\n",
        "\n",
        "Course Overview\n",
        "Write a detailed course overview that includes:\n",
        "- A clear description of what the course teaches.\n",
        "- 3–5 objectives written as bullet points.\n",
        "- A definition of the target audience, including skill level and prerequisites.\n",
        "\n",
        "Module Breakdown\n",
        "Create 5 modules. For each module, include:\n",
        "Module X: [Module Title]\n",
        "- Description: Write a 2–3 sentence explanation of what the module covers.\n",
        "- Key Learning Outcomes:\n",
        "  1. Outcome one\n",
        "  2. Outcome two\n",
        "  3. Outcome three\n",
        "- Interactive Assignment: Provide one hands‑on task, quiz, or activity.\n",
        "\n",
        "Assessment Plan\n",
        "Create a Markdown table with the following columns:\n",
        "| Assessment Method | Description | Weightage (%) |\n",
        "Include at least 3 assessment components with realistic weight distribution.\n",
        "\n",
        "Certification Criteria\n",
        "List the requirements a learner must meet to earn a certificate, such as:\n",
        "1. Minimum passing score\n",
        "2. Assignment completion\n",
        "3. Participation expectations\n",
        "\n",
        "Marketing Strategy\n",
        "Write a step‑by‑step marketing plan with 6–8 steps.\n",
        "Each step should include a short explanation of how to promote the course effectively.\n",
        "\n",
        "Produce only the final course outline in this exact structure and formatting.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        messages=[{\"role\": \"user\", \"content\": user_prompt}]\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Idiom Translations ===\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Course_Outline()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7c103ca",
      "metadata": {
        "id": "d7c103ca"
      },
      "source": [
        "\n",
        "=== Idiom Translations ===\n",
        "\n",
        "Course Outline: Mastering Prompt Engineering for AI Applications\n",
        "\n",
        "---\n",
        "\n",
        "**Course Overview**  \n",
        "This course provides a comprehensive introduction to prompt engineering—the process of designing and refining inputs to optimize AI model outputs. Learners will explore foundational concepts, practical techniques, and ethical considerations for crafting effective prompts across various AI applications. The curriculum emphasizes hands-on learning to empower beginners in harnessing the full potential of AI-driven tools in natural language processing.\n",
        "\n",
        "**Course Objectives**  \n",
        "- Understand core principles and terminology of prompt engineering.  \n",
        "- Develop skills to create clear, concise, and goal-oriented prompts.  \n",
        "- Analyze and improve prompt effectiveness through iterative testing.  \n",
        "- Apply prompt engineering strategies to real-world AI applications.  \n",
        "- Recognize ethical issues related to prompt design and AI output fairness.\n",
        "\n",
        "**Target Audience**  \n",
        "This course is designed for beginners with little to no background in AI or programming who are interested in leveraging AI tools effectively. No prior experience in machine learning or coding is required, though basic computer literacy and familiarity with web applications are helpful.\n",
        "\n",
        "---\n",
        "\n",
        "**Module Breakdown**\n",
        "\n",
        "**Module 1: Introduction to Prompt Engineering**  \n",
        "- Description: This module introduces the fundamental concepts of prompt engineering, explaining what prompts are and why they are crucial in interacting with AI models. Learners will get an overview of AI language models and their response mechanisms.  \n",
        "- Key Learning Outcomes:  \n",
        "  1. Define prompt engineering and its role in AI interactions.  \n",
        "  2. Understand how AI language models process prompts.  \n",
        "  3. Identify common use cases where prompt engineering is applied.  \n",
        "- Interactive Assignment: Write three different prompts for a simple AI text generation task and compare the responses to observe variations.\n",
        "\n",
        "---\n",
        "\n",
        "**Module 2: Crafting Effective Prompts**  \n",
        "- Description: Learners will explore best practices for writing clear, concise, and context-rich prompts to guide AI models toward desired outputs. The module covers prompt structure and language nuances.  \n",
        "- Key Learning Outcomes:  \n",
        "  1. Recognize components of clear and effective prompts.  \n",
        "  2. Experiment with prompt length, specificity, and tone.  \n",
        "  3. Evaluate prompt clarity through peer review and iteration.  \n",
        "- Interactive Assignment: Revise given sample prompts based on clarity and specificity guidelines, then test and analyze output improvements.\n",
        "\n",
        "---\n",
        "\n",
        "**Module 3: Techniques for Prompt Optimization**  \n",
        "- Description: This module focuses on iterative methods and experimental approaches such as zero-shot, few-shot, and chain-of-thought prompting to enhance AI responses. Learners will practice optimizing prompts to solve complex tasks.  \n",
        "- Key Learning Outcomes:  \n",
        "  1. Differentiate between zero-shot, few-shot, and chain-of-thought prompting.  \n",
        "  2. Apply iterative testing to refine prompt effectiveness.  \n",
        "  3. Measure and document prompt performance improvements.  \n",
        "- Interactive Assignment: Conduct an iterative prompt refinement cycle for a defined problem and submit a report on changes and results.\n",
        "\n",
        "---\n",
        "\n",
        "**Module 4: Prompt Engineering Across AI Applications**  \n",
        "- Description: Learners will explore how prompt engineering techniques are adapted to various AI applications, including chatbots, creative writing, data extraction, and summarization.  \n",
        "- Key Learning Outcomes:  \n",
        "  1. Identify domain-specific prompt strategies.  \n",
        "  2. Customize prompts for different AI-driven tasks.  \n",
        "  3. Integrate prompts into simple application workflows.  \n",
        "- Interactive Assignment: Design a prompt tailored for a chatbot to handle a customer service request and demonstrate its effectiveness.\n",
        "\n",
        "---\n",
        "\n",
        "**Module 5: Ethics and Future Trends in Prompt Engineering**  \n",
        "- Description: This module examines ethical concerns such as bias, misinformation, and user manipulation in AI outputs and discusses emerging trends and tools influencing prompt engineering.  \n",
        "- Key Learning Outcomes:  \n",
        "  1. Recognize ethical challenges in prompt design and AI output.  \n",
        "  2. Explore guidelines for responsible prompt crafting.  \n",
        "  3. Discover evolving tools and future directions in prompt engineering.  \n",
        "- Interactive Assignment: Participate in a discussion forum to analyze a case study involving biased AI outputs and propose ethical prompt adjustments.\n",
        "\n",
        "---\n",
        "\n",
        "**Assessment Plan**\n",
        "\n",
        "| Assessment Method           | Description                                         | Weightage (%) |\n",
        "|----------------------------|-----------------------------------------------------|---------------|\n",
        "| Module Quizzes             | Short quizzes after each module to reinforce learning concepts and terminology. | 30            |\n",
        "| Interactive Assignments    | Hands-on tasks that involve prompt writing, testing, and refinement with submitted reports or reflections. | 40            |\n",
        "| Final Project              | Design and present a comprehensive prompt solution for a specific AI application, including rationale and evaluation. | 30            |\n",
        "\n",
        "---\n",
        "\n",
        "**Certification Criteria**  \n",
        "1. Achieve a minimum passing score of 70% across all quizzes and assignments.  \n",
        "2. Complete and submit all interactive assignments and the final project.  \n",
        "3. Actively participate in at least three module discussion forums or peer reviews.  \n",
        "\n",
        "---\n",
        "\n",
        "**Marketing Strategy**  \n",
        "1. **Social Media Campaigns**  \n",
        "   Leverage platforms like LinkedIn, Twitter, and Instagram to post introductory videos, infographics, and learner testimonials to raise awareness.  \n",
        "2. **Email Newsletters**  \n",
        "   Send targeted emails to mailing lists at educational institutions, AI communities, and professional networks highlighting the course benefits and enrollment dates.  \n",
        "3. **Webinars and Live Demos**  \n",
        "   Host free live sessions showcasing prompt engineering basics and answering questions to generate interest and trust.  \n",
        "4. **Affiliate Partnerships**  \n",
        "   Collaborate with AI influencers, bloggers, and related course platforms to promote the course through reviews and referral discounts.  \n",
        "5. **Content Marketing**  \n",
        "   Publish blog posts, case studies, and how-to guides on prompt engineering tailored for beginners, driving organic traffic to the course landing page.  \n",
        "6. **Online Communities Engagement**  \n",
        "   Participate in AI, machine learning, and technology forums (Reddit, Discord, etc.) by sharing valuable insights and subtly promoting the course.  \n",
        "7. **Early Bird Discounts and Bundles**  \n",
        "   Offer limited-time discounts or bundle the course with complementary training programs to incentivize early registration.  \n",
        "8. **Certification Showcases**  \n",
        "   Highlight the certification's value for career advancement and include sample badges learners can display on LinkedIn profiles to attract aspirants focused on credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c72f50d9",
      "metadata": {
        "id": "c72f50d9"
      },
      "source": [
        "####"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}