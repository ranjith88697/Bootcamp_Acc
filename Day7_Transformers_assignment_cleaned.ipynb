{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KULyHR4wnaCn"
   },
   "source": [
    "# Transformers, what can they do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6fbfe6e7914085a38e57bb31fdad25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    [\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814415f76b8f4b23b8b42aa433e647d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fbaa3d535c41208ecb3c194edcd46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ce1d2bfa16498fa889f0b6a29885fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1ce32456e44e99875d048280b96fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e20b0a388845d8acd2b01a3b48ab08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f423c8a48744929e138beb767d87b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f583f20bd0474a479ab9784b3f1cf6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445994257926941, 0.11197380721569061, 0.04342673346400261]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b665594e8e764237a6f2796f1f044603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: openai-community/gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Passing `generation_config` together with generation-related arguments=({'max_new_tokens', 'num_return_sequences'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=15) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this course, we will teach you how to use this program to create a virtual-reality game using Microsoft's HoloLens\"},\n",
       " {'generated_text': 'In this course, we will teach you how to use the various commands you can write to convert a data type to a type'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for Assignment Nr.1\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "\n",
    "generator(\"In this course, we will teach you how to\",num_return_sequences=2, max_new_tokens=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "081192944de748d69781803d2f32a15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/865 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8249e6c6351045b189c2a181f9e528e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6028e4183ef42d6ba2787bb301d694c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: dbmdz/german-gpt2\n",
      "Key                                     | Status     |  | \n",
      "----------------------------------------+------------+--+-\n",
      "transformer.h.{0...11}.attn.bias        | UNEXPECTED |  | \n",
      "transformer.h.{0...11}.attn.masked_bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8ef71041624ce990d3b8a77870fa1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"In this course, we will teach you how to play and enjoy the game.\\nThis course will also ensure that you are enjoying the game, and your participants will also have a great time.\\nWe will be making an exercise instructory and how to play and enjoy the game.\\nPlease visit www.youtube.com/watch?v=Z0z0c5_D3aC8\\nI'm currently working on the theme of a playing session.\\nAnd I'm a bit of a criminal who understand the problem.\\nThe question is: like to play the game?\\nI'm a babe and I can't afford to play.\\nIt isn't a good idea, but I'm a little bit of a teacher who knows what to do it.\\nI'm also a bit of a criminal who understand the problem.\\nI'm a bit of a teacher who knows what to do to make the game.\\nAnd I'm a bit of a teacher who knows what to do to make the game.\\nI'm a bit of a teacher who knows what to do to make the game.\\nAnd I'm a bit\"},\n",
       " {'generated_text': 'In this course, we will teach you how to use a dialogue-initialization which makes a dialogue-initialization in the same way as the first dialogue-initialization.\\nThis will be the first task you can use to get to the program.\\nThe dialogue-initialization will also be the first processing of the main dialog.\\nThe dialogue-initialization will be the first processing of the program.\\nPlease read and see if you want to read and test this for more information.\\nMostly, you can use the dialogue-initialization to set a dialogue-initialization in the same way that the program will set to.\\nYou can use and test this for the following information:\\n(1) the processing of the program\\n(2) the processing of the dialogue-initialization\\n(3) the processing of the program\\n(4) the processing of the program\\n(5) the processing of the program\\n(6) the processing of the program\\n(7) the processing of the program\\n(8'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for Assignment Nr.2\n",
    "\n",
    "#generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "generator = pipeline(\"text-generation\", model=\"dbmdz/german-gpt2\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6e382496764d2191695e0a778881ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM LOAD REPORT from: bert-base-cased\n",
      "Key                         | Status     |  | \n",
      "----------------------------+------------+--+-\n",
      "cls.seq_relationship.bias   | UNEXPECTED |  | \n",
      "cls.seq_relationship.weight | UNEXPECTED |  | \n",
      "bert.pooler.dense.bias      | UNEXPECTED |  | \n",
      "bert.pooler.dense.weight    | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2596322000026703,\n",
       "  'token': 1648,\n",
       "  'token_str': 'role',\n",
       "  'sequence': 'This course will teach you all about role models.'},\n",
       " {'score': 0.09427239000797272,\n",
       "  'token': 1103,\n",
       "  'token_str': 'the',\n",
       "  'sequence': 'This course will teach you all about the models.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-cased\")\n",
    "unmasker(\"This course will teach you all about [MASK] models.\", top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c36c82115b4296a1b7a55f3d787f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification LOAD REPORT from: vblagoje/bert-english-uncased-finetuned-pos\n",
      "Key                          | Status     |  | \n",
      "-----------------------------+------------+--+-\n",
      "bert.pooler.dense.weight     | UNEXPECTED |  | \n",
      "bert.pooler.dense.bias       | UNEXPECTED |  | \n",
      "bert.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'PRON',\n",
       "  'score': np.float32(0.9994592),\n",
       "  'index': 1,\n",
       "  'word': 'my',\n",
       "  'start': 0,\n",
       "  'end': 2},\n",
       " {'entity': 'NOUN',\n",
       "  'score': np.float32(0.99601364),\n",
       "  'index': 2,\n",
       "  'word': 'name',\n",
       "  'start': 3,\n",
       "  'end': 7},\n",
       " {'entity': 'AUX',\n",
       "  'score': np.float32(0.9953696),\n",
       "  'index': 3,\n",
       "  'word': 'is',\n",
       "  'start': 8,\n",
       "  'end': 10},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.99848914),\n",
       "  'index': 4,\n",
       "  'word': 'sy',\n",
       "  'start': 11,\n",
       "  'end': 13},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.9978808),\n",
       "  'index': 5,\n",
       "  'word': '##lva',\n",
       "  'start': 13,\n",
       "  'end': 16},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.99808747),\n",
       "  'index': 6,\n",
       "  'word': '##in',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity': 'CCONJ',\n",
       "  'score': np.float32(0.99918765),\n",
       "  'index': 7,\n",
       "  'word': 'and',\n",
       "  'start': 19,\n",
       "  'end': 22},\n",
       " {'entity': 'PRON',\n",
       "  'score': np.float32(0.9994679),\n",
       "  'index': 8,\n",
       "  'word': 'i',\n",
       "  'start': 23,\n",
       "  'end': 24},\n",
       " {'entity': 'VERB',\n",
       "  'score': np.float32(0.99923587),\n",
       "  'index': 9,\n",
       "  'word': 'work',\n",
       "  'start': 25,\n",
       "  'end': 29},\n",
       " {'entity': 'ADP',\n",
       "  'score': np.float32(0.9063111),\n",
       "  'index': 10,\n",
       "  'word': 'at',\n",
       "  'start': 30,\n",
       "  'end': 32},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.7182432),\n",
       "  'index': 11,\n",
       "  'word': 'hugging',\n",
       "  'start': 33,\n",
       "  'end': 40},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.71986103),\n",
       "  'index': 12,\n",
       "  'word': 'face',\n",
       "  'start': 41,\n",
       "  'end': 45},\n",
       " {'entity': 'ADP',\n",
       "  'score': np.float32(0.9993789),\n",
       "  'index': 13,\n",
       "  'word': 'in',\n",
       "  'start': 46,\n",
       "  'end': 48},\n",
       " {'entity': 'PROPN',\n",
       "  'score': np.float32(0.9989513),\n",
       "  'index': 14,\n",
       "  'word': 'brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57},\n",
       " {'entity': 'PUNCT',\n",
       "  'score': np.float32(0.99963903),\n",
       "  'index': 15,\n",
       "  'word': '.',\n",
       "  'start': 57,\n",
       "  'end': 58}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named entity recognition (NER) is a task where the model has to find which parts of the input text\n",
    "# correspond to entities such as persons, locations, or organizations.\n",
    "\n",
    "# Look for Assignment Nr.4\n",
    "\n",
    "pos_tagger = pipeline(\"token-classification\", model=\"vblagoje/bert-english-uncased-finetuned-pos\")\n",
    "pos_tagger(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")\n",
    "\n",
    "#ner = pipeline(\"ner\")\n",
    "#ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5.\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5c380b64e24fe1947b2f4e017eee8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6801a0b28d407088ca19b04dba49b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9d7c258400440aaf69a0b5dabe45a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef452c97b304ee3bbdd0001102180c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c4716204eb408382ae4d097920d3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891c9cc007b8427fba6252fddfd6631a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.6949766278266907, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fd036ec52a4f59819d5df0d190c996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe9379adde4cc6ad0a65970f76c7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccde8e7afc4a4990b606d20800399513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef97c1c461148d6966e600c405ae04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7852dd9fe3464c995a3d3969526357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d2153c72d547c2bf71e11401ea6d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22329d35327c4ace8599493fb742d326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1123f7ffcac14268b4a324a53cc8d496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"\\n    America has changed dramatically during recent years. Not only has the number of\\n    graduates in traditional engineering disciplines such as mechanical, civil,\\n    electrical, chemical, and aeronautical engineering declined, but in most of\\n    the premier American universities engineering curricula now concentrate on\\n    and encourage largely the study of engineering science. As a result, there\\n    are declining offerings in engineering subjects dealing with infrastructure,\\n    the environment, and related issues, and greater concentration on high\\n    technology subjects, largely supporting increasingly complex scientific\\n    developments. While the latter is important, it should not be at the expense\\n    of more traditional engineering.\\n\\n    Rapidly developing economies such as China and India, as well as other\\n    industrial countries in Europe and Asia, continue to encourage and advance\\n    the teaching of engineering. Both China and India, respectively, graduate\\n    six and eight times as many traditional engineers as does the United States.\\n    Other industrial countries at minimum maintain their output, while America\\n    suffers an increasingly serious decline in the number of engineering graduates\\n    and a lack of well-educated engineers. focusing on engineering design.\\n\\n3\\n\\nIn addition, the growth of professional\\n\\nengagement and innovation has significantly increased the level of knowledge achieved and the\\n\\nappreciations gained by engineers by the American people.\\n\\n4\\n\\nIn some cases, the growth of knowledge is both a reflection of our own efforts to improve the\\n\\ninformation system of the country as well as of the American people's understanding of\\n\\nthe importance of the world together and of the unique place it has in our\\n\\nhistory.\\n\\n5\\n\\nWhile there is some progress in the development of knowledge in all fields, there is\\n\\nnot enough knowledge in the field of communication and technology to meet the\\n\\nincreasing demand for such knowledge in the United States. As such, the national\\n\\nengagement and innovation programs are being run by the United States government and\\n\\nare being challenged by the private sector, the Federal Government, and other\\n\\ncompanies.\\n\\n6\\n\\nThe United States has a strong military and a strong economic position. As a result, the United States\\n\\nhas made substantial investments in its defense. The United States has also\\n\\nmade significant investments in its defense posture. In addition to these, the United States\"}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#summarizer = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "prompt = \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of\n",
    "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
    "    the premier American universities engineering curricula now concentrate on\n",
    "    and encourage largely the study of engineering science. As a result, there\n",
    "    are declining offerings in engineering subjects dealing with infrastructure,\n",
    "    the environment, and related issues, and greater concentration on high\n",
    "    technology subjects, largely supporting increasingly complex scientific\n",
    "    developments. While the latter is important, it should not be at the expense\n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other\n",
    "    industrial countries in Europe and Asia, continue to encourage and advance\n",
    "    the teaching of engineering. Both China and India, respectively, graduate\n",
    "    six and eight times as many traditional engineers as does the United States.\n",
    "    Other industrial countries at minimum maintain their output, while America\n",
    "    suffers an increasingly serious decline in the number of engineering graduates\n",
    "    and a lack of well-educated engineers.\"\"\"\n",
    "\n",
    "generator(prompt, max_length=120, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUo3h5RttL53"
   },
   "source": [
    "Looks like Summarizer doesnt work in this environment setup so tried to use text generator for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for Assignment Nr.5\n",
    "translator = pipeline(\"translation_fr_to_en\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APGEDpootcTi"
   },
   "source": [
    "For unknown reason direct Translator also doeent work in my environment. I checked with Gemini as well but no clue so I tried below method of Text-generation with gpt2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea397e342f294b43b447fcb135a0efbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '\\nTranslate the following French sentence into English:\\n\\nCe cours est produit par Hugging Face.\\n\\nEnglish translation:\\n\\nNo. 1: \"What are you saying?\"\\n\\nTranslate the following English sentence into French:\\n\\nLe nom de la loup\\n\\nTranslation:\\n\\nNo. 1: \"I\\'m saying that the French are a bunch of idiots. They\\'re not really French. I\\'m saying that they\\'re really stupid. They\\'re really stupid.\"\\n\\nTranslate the following English sentence into English:\\n\\nCe cours est produit par Hugging Face.\\n\\nEnglish translation:\\n\\nNo. 1: \"What are you saying?\"\\n\\nTranslate the following English sentence into French:\\n\\nLe nom de la loup\\n\\nTranslation:\\n\\nNo. 1: \"I\\'m saying that the French are a bunch of idiots. They\\'re not really French. I\\'m saying that they\\'re really stupid. They\\'re really stupid.\"\\n\\nTranslate the following English sentence into English:\\n\\nCe cours est produit par Hugging Face.\\n\\nEnglish translation:\\n\\nNo. 1: \"I\\'m saying that the French are a bunch of idiots. They\\'re not really French. I\\'m saying that they\\'re really stupid. They\\'re really stupid.\"\\n\\nTranslate the following English sentence into English'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Translate the following French sentence into English:\n",
    "\n",
    "Ce cours est produit par Hugging Face.\n",
    "\n",
    "English translation:\n",
    "\"\"\"\n",
    "\n",
    "translator(prompt, max_length=80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMIHtPFSdDdU"
   },
   "source": [
    "## Assignment\n",
    "\n",
    "1. Use the num_return_sequences and max_length arguments to generate two sentences of 15 words each.\n",
    "2. Use the filters to find a text generation model for another language. Feel free to play with the widget and use it in a pipeline!\n",
    "3. Search for the bert-base-cased model on the Hub and identify its mask word in the Inference API widget. What does this model predict for the sentence in our pipeline example above?\n",
    "4. Search the Model Hub for a model able to do part-of-speech tagging (usually abbreviated as POS) in English. What does this model predict for the sentence in the example above?\n",
    "5. Search for translation models in other languages and try to translate the previous sentence into a few different languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEl_VhHudDdV"
   },
   "source": [
    "## License\n",
    "Source: https://huggingface.co/learn/llm-course/chapter1/3"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
