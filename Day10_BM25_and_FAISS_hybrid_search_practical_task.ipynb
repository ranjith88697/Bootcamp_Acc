{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjith88697/Bootcamp_Acc/blob/main/Day10_BM25_and_FAISS_hybrid_search_practical_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Goal: Create a code explanation for each cell as text below it.**"
      ],
      "metadata": {
        "id": "QEnnU_jebRv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating a hybrid search system using**\n",
        "* Embeddings for semantic search (sentence_transformers)\n",
        "* BM25 for keyword ranking (Sparse retrieval)\n",
        "* FAISS as a index.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u6yHJko66w17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IvZ-bss6DMRW",
        "outputId": "ecf8dcdc-b286-4831-c340-0ba2215801cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.3)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.10.0+cpu)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (0.24.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This command installs the Sentence Transformers library, which provides  embedding models to perform Semantic Search"
      ],
      "metadata": {
        "id": "cLAQBsAzvFjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tAWS96qHKUst",
        "outputId": "53c87cde-f932-4ff7-da8b-495fd52fe645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This installs rank_bm25, a lightweight Python implementation of the BM25 ranking algorithm.\n",
        "BM25 is a classic sparse retrieval method that scores documents based on keyword frequency and relevance. This gives your hybrid system the ability to capture exact keyword matches"
      ],
      "metadata": {
        "id": "R3WnGFNAvcB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qkfw4AxtKh0N",
        "outputId": "2f76b194-771e-4fd3-d60e-356d52c25c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (26.0)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This installs FAISS, a fast vector similarity search library developed by Meta.\n",
        "FAISS used to build an index of dense embeddings and perform efficient nearest neighbor search."
      ],
      "metadata": {
        "id": "Dm5AXaKuvsl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentence_transformers"
      ],
      "metadata": {
        "id": "zLwrdS03DZM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell loads all the core libraries required for building a hybrid search system:\n",
        "\n",
        "sentence_transformers: Provides pretrained embedding models that convert text into dense vectors for semantic search."
      ],
      "metadata": {
        "id": "TeLCBZBwwNvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss"
      ],
      "metadata": {
        "id": "_OBXdCf1KO6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell loads all the core libraries required for building a hybrid search system:\n",
        "\n",
        "numpy  \n",
        "Used for numerical operations, especially when preparing vectors for FAISS.\n",
        "\n",
        "rank_bm25.BM25Okapi  \n",
        "Implements the BM25 algorithm, a classic keyword based ranking method. This gives the sparse retrieval capabilities.\n",
        "\n",
        "faiss  \n",
        "A high performance similarity search library used to index and query dense embeddings efficiently."
      ],
      "metadata": {
        "id": "VO_1HfywXfrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"Artificial Intelligence is changing the world.\",\n",
        "    \"Machine Learning is a subset of AI.\",\n",
        "    \"Deep Learning is a subset of Machine Learning.\",\n",
        "    \"Natural Language Processing involves understanding text.\",\n",
        "    \"Computer Vision allows machines to see and understand.\",\n",
        "    \"AI includes areas like NLP and Computer Vision.\",\n",
        "    \"The Pyramids of Giza are architectural marvels.\",\n",
        "    \"Mozart was a prolific composer during the classical era.\",\n",
        "    \"Mount Everest is the tallest mountain on Earth.\",\n",
        "    \"The Nile is one of the world's longest rivers.\",\n",
        "    \"Van Gogh's Starry Night is a popular piece of art.\",\n",
        "    \"Basketball is a sport played with a round ball and two teams.\"\n",
        "]"
      ],
      "metadata": {
        "id": "FCCbrmadKy_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell defines a small corpus of documents that the hybrid search system will index and search over.\n",
        "The list intentionally mixes: AI related content (NLP, Computer Vision, Machine Learning) and General knowledge topics (geography, art, sports)\n",
        "\n",
        "This variety makes it easier to test whether the search system can correctly identify which documents are relevant to a given query — especially when the query is about AI."
      ],
      "metadata": {
        "id": "NzuI-on4w3rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Tell me about AI in text and vision.\""
      ],
      "metadata": {
        "id": "TFnYitfsK4N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the user query the hybrid search system will process.\n",
        "It references: (AI, Text relates to NLP and Vision relates to Computer Vision)\n",
        "\n",
        "This makes it a great test case because relevant information is spread across multiple documents.\n",
        "The hybrid system will use BM25 to match keywords like “AI”, “text”, “vision”\n",
        "\n",
        "Use embeddings + FAISS to capture semantic meaning (e.g., “NLP” ≈ “text understanding”)"
      ],
      "metadata": {
        "id": "Tf5pFnEcXhg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_corpus = [doc.split(\" \") for doc in documents]"
      ],
      "metadata": {
        "id": "7hkP0wLfLVBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line prepares the documents for BM25 by splitting each document into a list of individual tokens.\n",
        "BM25 works on tokenized text, so this step converts the raw strings into the format BM25 expects."
      ],
      "metadata": {
        "id": "D9b4PNENXkBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bm25 = BM25Okapi(tokenized_corpus)"
      ],
      "metadata": {
        "id": "XV9NIluDLVMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The BM25Okapi object using the tokenized documents.\n",
        "This builds the internal BM25 index, enabling keyword based scoring.\n",
        "BM25 will help identify documents that contain important query terms like AI, text, or vision."
      ],
      "metadata": {
        "id": "VQ801PaFXlW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-f4lRUEiMbpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loads a pretrained SentenceTransformer model that converts text into dense vector embeddings.\n",
        "The chosen model, paraphrase-MiniLM-L6-v2, is lightweight and fast while still providing strong semantic understanding."
      ],
      "metadata": {
        "id": "JCDhiGXjzmT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings = model.encode(documents)"
      ],
      "metadata": {
        "id": "Q4KfO6jDM2qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line encodes every document into a numerical vector.\n",
        "Each vector captures the meaning of the document, allowing the system to find semantically similar text even when exact keywords dont match.\n",
        "These vectors will later be indexed by FAISS for fast similarity search."
      ],
      "metadata": {
        "id": "1dbtEyChXm4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.IndexFlatL2(document_embeddings.shape[1])"
      ],
      "metadata": {
        "id": "EI5rnxhWNLxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a FAISS index configured for L2 (Euclidean) distance.\n",
        "The dimension of the index is set to match the embedding size.\n",
        "FAISS will allow you to perform efficient nearest neighbor searches over the embedding space."
      ],
      "metadata": {
        "id": "WFYIQLRPXoc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.add(np.array(document_embeddings).astype('float32'))\n"
      ],
      "metadata": {
        "id": "L9MH_awBPO_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FAISS requires vectors in float32 format, so the embeddings are converted and added to the index.\n",
        "Once added, the index is ready to perform fast semantic similarity searches for any query embedding you generate."
      ],
      "metadata": {
        "id": "zrURSKfqXseY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_n =10"
      ],
      "metadata": {
        "id": "EnPq9M0DP8xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This sets the number of top BM25-ranked documents for the hybrid search step.\n",
        "Instead of searching the entire corpus the candidate set to the 10 most keyword relevant documents, which makes the semantic search faster and more focused."
      ],
      "metadata": {
        "id": "2UieLj6tYBzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bm25_scores = bm25.get_scores(query.split(\" \"))"
      ],
      "metadata": {
        "id": "V0UPGo6APiRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BM25 scores each document based on how well its tokens match the query tokens.\n",
        "Splitting the query into words ensures BM25 can evaluate term frequency and relevance. The result is a list of numerical scores—one per document."
      ],
      "metadata": {
        "id": "oWg2bjTYYDK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_docs_indices = np.argsort(bm25_scores)[-top_n:]"
      ],
      "metadata": {
        "id": "QbtSQ7IcP4m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line sorts the BM25 scores and extracts the indices of the top 10 highest scoring documents will be passed to semantic stage."
      ],
      "metadata": {
        "id": "IFb7NY9qYEjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_docs_embeddings = [document_embeddings[i] for i in top_docs_indices]"
      ],
      "metadata": {
        "id": "OzjKHo_bQN7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here you gather the dense embeddings for only the BM25 selected documents.\n",
        "This reduces the search space and allows FAISS to perform a more efficient and meaningful semantic comparison."
      ],
      "metadata": {
        "id": "su55p26DYFzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = model.encode([query])"
      ],
      "metadata": {
        "id": "zXNjn6CFQf2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The query is converted into a dense vector using the same SentenceTransformer model used for the documents.\n",
        "This ensures the query and documents live in the same semantic space"
      ],
      "metadata": {
        "id": "py-06iU4YG_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_index = faiss.IndexFlatL2(top_docs_embeddings[0].shape[0])"
      ],
      "metadata": {
        "id": "3ol-AtOvQslF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This initializes a new FAISS index this time only for the top BM25 documents.\n",
        "The index uses L2 distance and is sized according to the embedding dimension."
      ],
      "metadata": {
        "id": "bgHBKN_pYHvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_index.add(np.array(top_docs_embeddings).astype('float32'))"
      ],
      "metadata": {
        "id": "EaYHCzfUQ2qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This adds the embeddings of the BM25 selected documents into the FAISS sub index.\n",
        "FAISS requires vectors in float32 format, so the embeddings are converted before insertion. Once added, the sub index becomes ready for fast semantic similarity search."
      ],
      "metadata": {
        "id": "jNhKpZQ9YItr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_,sub_dense_ranked_indices = sub_index.search(np.array(query_embedding).astype('float32'), top_n)"
      ],
      "metadata": {
        "id": "JoxIlrNGRB0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This performs a FAISS search using the query embedding.\n",
        "FAISS returns the indices of the most semantically similar documents within the BM25 filtered subset.\n",
        "\n",
        "The underscore _ captures distances, while sub_dense_ranked_indices contains the ranked positions."
      ],
      "metadata": {
        "id": "PA_ORI-7Ye3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_dense_ranked_indices\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUznIK1WU1bO",
        "outputId": "2cb36897-5113-4e14-cf44-097c82468fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9, 8, 1, 0, 6, 7, 2, 4, 3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output shows the order of the top documents within the sub index.\n",
        "Each number refers to a position inside the BM25 filtered list"
      ],
      "metadata": {
        "id": "LvqNlcPpYgNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_ranked_indices = [top_docs_indices[i] for i in sub_dense_ranked_indices[0]]"
      ],
      "metadata": {
        "id": "tLISuVFGRPfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the key step that merges sparse and dense retrieval.\n",
        "\n",
        "This step translates the FAISS ranking back into the original document indices.\n",
        "It has a final list of document positions ranked by semantic similarity only with in relevant BM25 candidate list"
      ],
      "metadata": {
        "id": "qG-hk0vWYlry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_docs = [documents[i] for i in final_ranked_indices]"
      ],
      "metadata": {
        "id": "80L1IIeORa2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This extracts the actual text of the documents in their final hybrid ranked order. The result is a list of documents that are both:\n",
        "\n",
        "Keyword relevant\n",
        "\n",
        "Semantically aligned with the query (ranked by FAISS)"
      ],
      "metadata": {
        "id": "ZKb0Q5m0Ywt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqvFfA4vRjBT",
        "outputId": "e19c50ef-9d78-441a-814b-2a684e771959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI includes areas like NLP and Computer Vision.',\n",
              " 'Computer Vision allows machines to see and understand.',\n",
              " 'Natural Language Processing involves understanding text.',\n",
              " 'Deep Learning is a subset of Machine Learning.',\n",
              " \"Van Gogh's Starry Night is a popular piece of art.\",\n",
              " 'Basketball is a sport played with a round ball and two teams.',\n",
              " 'Mozart was a prolific composer during the classical era.',\n",
              " \"The Nile is one of the world's longest rivers.\",\n",
              " 'The Pyramids of Giza are architectural marvels.',\n",
              " 'Mount Everest is the tallest mountain on Earth.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Provide a brief description of the process this code implements."
      ],
      "metadata": {
        "id": "ffEg7OeOY8V2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements a hybrid document retrieval system that combines keyword based search (BM25) with semantic vector search (SentenceTransformers + FAISS) to return the most relevant documents for a user query.\n",
        "\n",
        "The workflow follows these steps:\n",
        "\n",
        "- Prepare the data by loading documents and defining a query.\n",
        "\n",
        "- Build a BM25 index to score documents based on keyword overlap with the query.\n",
        "\n",
        "- Select the top BM25 candidates, narrowing the search space to the most likely matches.\n",
        "\n",
        "- Generate dense embeddings for both documents and the query using a SentenceTransformer model.\n",
        "\n",
        "- Use FAISS to perform fast semantic similarity search among the BM25 filtered documents.\n",
        "\n",
        "- Rerank the candidates based on semantic similarity and return the final ordered list of relevant documents.\n",
        "\n",
        "Overall, the system first filters documents using keywords, then reranks them using meaning, giving more accurate and efficient search result than either method alone."
      ],
      "metadata": {
        "id": "50nikWs1Zqrp"
      }
    }
  ]
}